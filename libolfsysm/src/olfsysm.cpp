


#include "olfsysm.hpp"

#include <math.h>
#include <fstream>
#include <vector>
#include <string>
#include <algorithm>
#include <random>
#include <iostream>
#include <functional>
#include <sstream>
#include <cassert>
#include <unordered_set>
#include <iomanip>
#include <set>
#include <map>
#include <cmath>
#include <stdexcept>


/* So code can be compiled single threaded, to support debugging.
 * Only other OMP references should be in the preprocessor directives, which I think can
 * just be ignored (though that will generate compilation warning, which is good).
 * https://stackoverflow.com/questions/7847900 */
#ifdef _OPENMP
   #include <omp.h>
#else
   #define omp_get_thread_num() 0
#endif



Logger::Logger() {}
Logger::Logger(Logger const&) {
    throw std::runtime_error("Can't copy Logger instances.");
}


void Logger::operator()(std::string const& msg) const {
    std::lock_guard<std::mutex> lock(mtx);
    if (!fout) return;
    fout << msg << std::endl;
}
void Logger::operator()() const {
    this->operator()("");
}

void Logger::redirect(std::string const& path) {
    std::lock_guard<std::mutex> lock(mtx);
    fout.close();
    fout.open(path, std::ofstream::out | std::ofstream::app);
}
void Logger::disable() {
    std::lock_guard<std::mutex> lock(mtx);
    fout.close();
}

/* Concatenate all the given arguments, which can be of any type, into one
 * string. No separator is placed between the arguments! */
template<class... Args>
std::string cat(Args&&... args) {
    std::stringstream ss;
    (ss << ... << std::forward<Args>(args));
    return ss.str();
}

/* For random number generation. */
// NOTE: g_randdev only used in definition of g_randgen
// TODO TODO would this not need a mutex across threads? is one in use somewhere?
// diff seed for each thread too?
// https://stackoverflow.com/questions/21237905
thread_local std::random_device g_randdev;
thread_local std::mt19937 g_randgen{g_randdev()};

ModelParams const DEFAULT_PARAMS = []() {
    ModelParams p;

    p.time.pre_start  = -2.0;
    p.time.start      = -0.5;
    p.time.end        = 0.75;
    p.time.stim.start = 0.0;
    p.time.stim.end   = 0.5;
    p.time.dt         = 0.5e-3;

    p.orn.taum             = 0.01;
    p.orn.n_physical_gloms = 51;

    p.ln.taum   = 0.01;
    p.ln.tauGA  = 0.1;
    p.ln.tauGB  = 0.4;
    p.ln.thr    = 1.0;
    p.ln.inhsc  = 500.0;
    p.ln.inhadd = 200.0;

    p.pn.taum       = 0.01;
    p.pn.offset     = 2.9410;
    p.pn.tanhsc     = 5.3395;
    p.pn.inhsc      = 368.6631;
    p.pn.inhadd     = 31.4088;
    p.pn.noise.mean = 0.0;
    p.pn.noise.sd   = 0.0;

    p.kc.N                     = 2000;
    p.kc.nclaws                = 6;
    p.kc.uniform_pns           = false;
    p.kc.pn_drop_prop          = 0.0;
    p.kc.preset_wPNKC          = false;
    p.kc.seed                  = 0;
    p.kc.tune_apl_weights      = true;
    p.kc.preset_wAPLKC         = false;
    p.kc.preset_wKCAPL         = false;
    p.kc.ignore_ffapl          = false;
    p.kc.fixed_thr             = 0;
    p.kc.add_fixed_thr_to_spont= false;
    p.kc.use_fixed_thr         = false;
    p.kc.use_vector_thr        = false;
    p.kc.use_homeostatic_thrs  = true;
    p.kc.thr_type              = "";
    p.kc.sp_target             = 0.0915;
    p.kc.sp_factor_pre_APL     = 2.0;
    p.kc.sp_acc                = 0.1;
    p.kc.sp_lr_coeff           = 1.0; 
    p.kc.sp_lr_coeff_cl        = 0.7;
    p.kc.max_iters             = 30;  
    p.kc.apltune_subsample     = 1;

    // TODO doc how each of these are diff (w/ units if i can). not currently mentioned
    // in .hpp file
    p.kc.taum                  = 0.01;
    p.kc.apl_taum              = 0.05;
    p.kc.tau_apl2kc            = 0.01;

    p.kc.tau_r                 = 1.0;
    // olfsysm.hpp says that setting this to 0 should disable synaptic depression
    // (tau_r above is another parameter for synaptic depression)
    p.kc.ves_p                 = 0.0;

    p.kc.save_vm_sims          = true;
    p.kc.save_spike_recordings = true;
    p.kc.save_nves_sims        = true;
    p.kc.save_inh_sims         = true;
    p.kc.save_Is_sims          = true;

    p.ffapl.taum         = p.kc.apl_taum;
    p.ffapl.w            = 1.0;             // appropriate for LTS
    p.ffapl.coef         = "lts";
    p.ffapl.zero         = true;
    p.ffapl.nneg         = true;
    p.ffapl.gini.a       = 1.0;
    p.ffapl.gini.source  = "(-s)/s";
    p.ffapl.lts.m        = 1.5;
    
    p.kc.kc_ids.clear();
    p.kc.wPNKC_one_row_per_claw = false; 
    return p;
}();

/* (utility) Split a string by commas, and fill vec with the segments.
 * vec must be sized correctly! */
void split_regular_csv(std::string const& str, std::vector<std::string>& vec);

/* The exponential ('e') part of the smoothts MATLAB function included in the
 * Kennedy source.
 * Instead of returning the smoothed matrix, it smooths it in-place. */
void smoothts_exp(Matrix& vin, double wsize);

/* Fill out with numbers generated by rng. */
void add_randomly(std::function<double()> rng, Matrix& out);

/* Calculate the Gini-type FFAPL coefficient. */
double ffapl_coef_gini(ModelParams const& p,
        Column const& pn, Column const& pn_spont);

/* Calculate the lifetime sparseness FFAPL coefficient. */
double ffapl_coef_lts(ModelParams const& p,
        Column const& pn, Column const& pn_spont);

/* Build PNKC connectivity matrix w in place, with glom choice weighted by cxnd
 * and drop_prop (see ModelParams). */
void build_wPNKC_from_cxnd(
        Matrix& w, unsigned nc, Row const& cxnd, double drop_prop);

/* Build wPNKC as specified by the ModelParams. */
void build_wPNKC(ModelParams const& p, RunVars& rv);

/* Sample spontaneous PN output from odor 0. */
Column sample_PN_spont(ModelParams const& p, RunVars const& rv);

/* Decide a KC threshold column from KC membrane voltage data. */
Column choose_KC_thresh(
        ModelParams const& p, Matrix& KCpks, Column const& spont_in);

/* Remove all columns <step in timecourse.*/
void remove_before(unsigned step, Matrix& timecourse);
/* Remove all pretime columns in all timecourses in r. */
void remove_all_pretime(ModelParams const& p, RunVars& r);

/* Get the list of odors that should be simulated (non-tuning). */
std::vector<unsigned> get_simlist(ModelParams const& p);

/*******************************************************************************
********************************************************************************
*********************                                      *********************
*********************            IMPLEMENTATIONS           *********************
*********************                                      *********************
********************************************************************************
*******************************************************************************/
inline unsigned get_ngloms(ModelParams const& mp) {
    return mp.orn.data.delta.rows();
}
inline unsigned get_nodors(ModelParams const& mp) {
    return mp.orn.data.delta.cols();
}

ModelParams::Time::Time() : stim(*this) {
}
ModelParams::Time::Time(Time const& o) : stim(*this) {
    pre_start  = o.pre_start;
    start      = o.start;
    end        = o.end;
    stim.start = o.stim.start;
    stim.end   = o.stim.end;
    dt         = o.dt;
}
ModelParams::Time::Stim::Stim(ModelParams::Time& o) : _owner(o) {
}
unsigned ModelParams::Time::Stim::start_step() const {
    return (start - _owner.pre_start)/_owner.dt;
}
unsigned ModelParams::Time::Stim::end_step() const {
    return (end - _owner.pre_start)/_owner.dt;
}
Row ModelParams::Time::Stim::row_all() const {
    Row ret(1, _owner.steps_all());
    ret.setZero();
    for (unsigned i = start_step(); i < end_step(); i++) {
        ret(i) = 1.0;
    }
    return ret;
}
unsigned ModelParams::Time::start_step() const {
    return (start-pre_start)/dt;
}
unsigned ModelParams::Time::steps_all() const {
    return (end-pre_start)/dt;
}
unsigned ModelParams::Time::steps() const {
    return (end-start)/dt;
}
Row ModelParams::Time::row_all() const {
    Row ret(1, steps_all());
    ret.setOnes();
    return ret;
}

RunVars::RunVars(ModelParams const& p) : orn(p), ln(p), pn(p), ffapl(p), kc(p) {
}
RunVars::ORN::ORN(ModelParams const& p) :
    sims(get_nodors(p), Matrix(get_ngloms(p), p.time.steps_all())) {
}
RunVars::LN::LN(ModelParams const& p) :
    inhA{std::vector<Vector>(get_nodors(p), Row(1, p.time.steps_all()))},
    inhB{std::vector<Vector>(get_nodors(p), Row(1, p.time.steps_all()))} {
}
RunVars::PN::PN(ModelParams const& p) :
    sims(get_nodors(p), Matrix(get_ngloms(p), p.time.steps_all())) {
}
RunVars::FFAPL::FFAPL(ModelParams const& p) :
    vm_sims(get_nodors(p), Row(1, p.time.steps_all())),
    coef_sims(get_nodors(p), Row(1, p.time.steps_all())) {
    for (auto& v : vm_sims) {
        v.setZero();
    }
}
RunVars::KC::KC(ModelParams const& p) :
    wPNKC(
        p.kc.wPNKC_one_row_per_claw 
        ? int(p.kc.kc_ids.size()) 
        : int(p.kc.N),
        get_ngloms(p)
    ),
    
    wAPLKC( p.kc.wPNKC_one_row_per_claw ? int(p.kc.kc_ids.size()) : int(p.kc.N), 1 ),
    wKCAPL( 1, p.kc.wPNKC_one_row_per_claw ? int(p.kc.kc_ids.size()) : int(p.kc.N) ),

    wAPLKC_scale(1.0),
    wKCAPL_scale(1.0),

    thr(p.kc.N, 1),
    responses(p.kc.N, get_nodors(p)),
    spike_counts(p.kc.N, get_nodors(p)),

    vm_sims(p.kc.save_vm_sims ? get_nodors(p) : 0,
            Matrix(p.kc.N, p.time.steps_all())),
    spike_recordings(p.kc.save_spike_recordings ? get_nodors(p) : 0,
            Matrix(p.kc.N, p.time.steps_all())),
    nves_sims(p.kc.save_nves_sims ? get_nodors(p) : 0,
            Matrix(p.kc.N, p.time.steps_all())),
    inh_sims(p.kc.save_inh_sims ? get_nodors(p) : 0,
            Matrix(1, p.time.steps_all())),
    Is_sims(p.kc.save_Is_sims ? get_nodors(p) : 0,
            Matrix(1, p.time.steps_all())),
    tuning_iters(0)
{
    if (p.kc.wPNKC_one_row_per_claw) {
        std::cerr << "[KC] ctor begin\n";
        const auto& raw = p.kc.kc_ids;  // One body ID per claw
        claw_to_kc.resize(raw.size());

        std::unordered_map<unsigned, int> id2idx;
        int nextIndex = 0;

        for (size_t i = 0; i < raw.size(); ++i) {
            unsigned bid = raw[i];
            auto it = id2idx.find(bid);
            if (it == id2idx.end()) {
                id2idx[bid] = nextIndex;
                claw_to_kc(i) = nextIndex++;
            } else {
                claw_to_kc(i) = it->second;
            }
        }

        // Optional safety check: confirm number of unique KCs matches expected N
        assert(nextIndex == int(p.kc.N) && "Number of unique KC IDs must equal p.kc.N");
        std::cerr << "[KC] ctor end; claws=" << claw_to_kc.size() << '\n';
    } else {
        std::cerr << "claw_to_kc are not created\n";
        claw_to_kc.resize(0);  // For clarity, make sure it's empty
    }
}


void split_regular_csv(std::string const& str, std::vector<std::string>& vec) {
    int seg = 0;
    std::string growing;
    for (char ch : str) {
        if (ch == ',') {
            vec[seg++] = growing;
            growing = "";
        }
        else {
            growing += ch;
        }
    }
    vec[vec.size()-1] = growing;
}

/* Helper function for load_hc_data(). */
void load_hc_data_line(
        std::string const& line, std::vector<std::string>& segs,
        Matrix& out, unsigned col) {
    unsigned const N_HC_GLOMS  = 23;
    split_regular_csv(line, segs);
    unsigned g8fix = 0; // decrement the column ID of odors after glom 8
    for (unsigned glom = 0; glom < N_HC_GLOMS+1; glom++) {
        /* Ignore the 8th glom column (Kennedy does this). */
        if (glom == 7) {
            g8fix = 1;
            continue;
        }

        out(glom-g8fix, col) = std::stod(segs[glom+2]);
    }
}
void load_hc_data(ModelParams& p, std::string const& fpath) {
    unsigned const N_HC_ODORS  = 110; // all original HC odors
    unsigned const N_HC_GLOMS  = 23;  // all good HC gloms
    unsigned const N_ODORS_ALL = 186; // all odors in Kennedy's HC data file

    // TODO is it an issue if input data exceeds these sizes? or where else if resizing
    // happening? just setting directly via pybind11 work? add tests to check?
    p.orn.data.delta.resize(N_HC_GLOMS, N_HC_ODORS);
    p.orn.data.spont.resize(N_HC_GLOMS, 1);

    std::ifstream fin(fpath);
    std::string line;

    /* Discard the first two (header) lines. */
    std::getline(fin, line);
    std::getline(fin, line);

    /* Read the rest of the lines (except the last one). */
    std::vector<std::string> segs(N_HC_GLOMS+2+1); // 2 ID cols, 1 bad glom col
    for (unsigned odor = 0; odor < N_ODORS_ALL; odor++) {
        std::getline(fin, line);

        /* We need to read to the end of the file, but we aren't interested in
         * any of the the non-HC odors. */
        if (odor >= N_HC_ODORS) continue;

        /* Parse and store data. */
        load_hc_data_line(line, segs, p.orn.data.delta, odor);
    }

    /* Load the spontaneous rates line. */
    std::getline(fin, line);
    load_hc_data_line(line, segs, p.orn.data.spont, 0);

    /* Load connectivity distribution data. */
    p.kc.cxn_distrib.resize(1, N_HC_GLOMS);
    // TODO move cxn_distrib init to default params (out from load_hc_data at least)?
    // or move to separate fn to just init that (and only call that fn, not
    // load_hc_data, for cases in mb_model where we only need cxn_distrib)?
    /* Data presumably taken from some real measurements.
     * Taken from Kennedy source. */
    p.kc.cxn_distrib <<
        2.0, 24.0, 4.0, 30.0, 33.0, 8.0, 0.0,
        // no #8!
        29.0, 6.0, 2.0, 4.0, 21.0, 18.0, 4.0,
        12.0, 21.0, 10.0, 27.0, 4.0, 26.0, 7.0,
        26.0, 24.0;
}

void smoothts_exp(Matrix& vin, double wsize) {
    double extarg = wsize;
    if (wsize > 1.0) {
        extarg = 2.0/(wsize+1.0);
    }
    for (int i = 1; i < vin.cols(); i++) {
        vin.col(i) = extarg*vin.col(i) + (1-extarg)*vin.col(i-1);
    }
}

void add_randomly(std::function<double()> rng, Matrix& out) {
    for (unsigned i = 0; i < out.rows(); i++) {
        for (unsigned j = 0; j < out.cols(); j++) {
            out(i, j) += rng();
        }
    }
}

double ffapl_coef_gini(ModelParams const& p,
        Column const& pn, Column const& spont) {
    Column src;
    if (p.ffapl.gini.source == "=")
        src = pn;
    else if (p.ffapl.gini.source == "-spont")
        src = pn-spont;
    else if (p.ffapl.gini.source == "/spont")
        src = pn.array()/spont.array();
    else if (p.ffapl.gini.source == "(-s)/s")
        src = (pn-spont).array()/spont.array();
    else
        return 1.0;

    double mu = src.mean();
    if (abs(mu) < 1e-5)
        return 1.0;

    int n = src.size();
    double g = 0.0;
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < n; j++) {
            g += abs(src(i)-src(j));
        }
    }

    double dn = double(n);
    g = 1.0 - p.ffapl.gini.a*g/(2.0*dn*dn*mu);
    if (g < 0.0)
        g = 0.0;

    return g;
}

double ffapl_coef_lts(ModelParams const& p,
        Column const& pn, Column const& spont) {
    Column delta = pn-spont;
    delta = (delta.array() < 0).select(0, delta);

    if ((delta.array()/spont.array()).abs().maxCoeff() < 0.05) {
        // <5% change from spont in all channels
        return 1.0;
    }

    double L = pow(delta.sum(), 2.0)/(delta.array()*delta.array()).sum();
    L =  (1.0 - L/delta.size())/(1.0 - 1.0/delta.size());
    if (isnan(L)) {
        L = 1.0;
    }

    double m = p.ffapl.lts.m;
    return m + L*(1.0-m);
}

void build_wPNKC_from_cxnd(
        Matrix& w, unsigned nc, Row const& cxnd, double drop_prop) {
    w.setZero();
    std::vector<double> flat(cxnd.size());
    double sum = 0;
    for (unsigned i = 0; i < cxnd.size(); i++) {
        flat[i] = cxnd(0, i);
        sum += flat[i];
    }
    flat.push_back(drop_prop*sum/(1.0-drop_prop));
    std::discrete_distribution<int> dd(flat.begin(), flat.end());
    for (unsigned kc = 0; kc < w.rows(); kc++) {
        for (unsigned claw = 0; claw < nc; claw++) {
            int idx = dd(g_randgen);
            if (idx < cxnd.size()) {
                w(kc, idx) += 1.0;
            }
        }
    }
}
void build_wPNKC(ModelParams const& p, RunVars& rv) {
    if (p.kc.preset_wPNKC) return;
    if (p.kc.seed != 0) {
        g_randgen.seed(p.kc.seed);
        rv.log(cat("build_wPNKC: g_randgen seed=", p.kc.seed ));
    }
    unsigned nc = p.kc.nclaws;
    double pdp = p.kc.pn_drop_prop;
    if (p.kc.uniform_pns) {
        rv.log("building UNIFORM connectivity matrix");
        // TODO also log nc? other things? what's going on w/ seed?
        // TODO can i even repro old checks against matt's stuff from model_test.py?

        // TODO delete
        rv.log(cat("get_ngloms: ", get_ngloms(p) ));
        // should be N KCs
        rv.log(cat("wPNKC.rows(): ", rv.kc.wPNKC.rows() ));
        // should be same as get_ngloms(p)?
        rv.log(cat("wPNKC.cols(): ", rv.kc.wPNKC.cols() ));
        //
        Row cxnd(1, get_ngloms(p));
        cxnd.setOnes();
        // TODO modify to add logging / duplicate up here to inspect output of rng
        build_wPNKC_from_cxnd(rv.kc.wPNKC, nc, cxnd, pdp);
    }
    else {
        rv.log("building WEIGHTED connectivity matrix");
        build_wPNKC_from_cxnd(rv.kc.wPNKC, nc, p.kc.cxn_distrib, pdp);
    }
    // TODO what is this doing? currents size an issue?
    // .currents not referenced anywhere else anyway...
    if (p.kc.currents.size()) {
        // TODO delete (not actually running anyway)
        rv.log("multiplying wPNKC by kc.currents.asDiagonal()");
        //

        rv.kc.wPNKC *= p.kc.currents.asDiagonal();
        // TODO delete. did i add this line or was it from matt? i assume it's equiv to
        // above?
        //rv.kc.wPNKC = rv.kc.wPNKC.array().colwise() * p.kc.currents.array();
    }
}
Column sample_PN_spont(ModelParams const& p, RunVars const& rv) {
    /* Sample from halfway between time start and stim start to stim start. */
    unsigned sp_t1 =
        p.time.start_step()
        + unsigned((p.time.stim.start-p.time.start)/(2*p.time.dt));
    unsigned sp_t2 =
        p.time.start_step()
        + unsigned((p.time.stim.start-p.time.start)/(p.time.dt));
    return rv.pn.sims[0].block(0,sp_t1,get_ngloms(p),sp_t2-sp_t1).rowwise().mean();
}
Column choose_KC_thresh_uniform(
        ModelParams const& p, Matrix& KCpks, Column const& spont_in) {
    unsigned tlist_sz = KCpks.cols();
    KCpks.resize(1, KCpks.size());                     // flatten
    std::sort(KCpks.data(), KCpks.data()+KCpks.size(),
            [](double a, double b){return a>b;});      // dec. order
    // TODO TODO log what we would get if we used values +/- 1 from the index used for
    // KCpks? (to try to figure out limits of precision in sparsity achievable through
    // setting threshold alone)
    double thr_const = KCpks(std::min(
        int(p.kc.sp_target * p.kc.sp_factor_pre_APL * double(p.kc.N*tlist_sz)),
        int(p.kc.N*tlist_sz)-1));
    return thr_const + spont_in.array()*2.0;
}
Column choose_KC_thresh_homeostatic(
        ModelParams const& p, Matrix& KCpks, Column const& spont_in) {
    /* Basically do the same procedure as the uniform algorithm, but do it for
     * each KC (row) separately instead of all together.
     * To sort each row in place, we first flatten the entire list, and then
     * sort portions of it in place. This is an unfortunate consequence of the
     * lack of stl iterators in Eigen <=3.4. */
    Column thr = 2.0*spont_in;
    unsigned cols = KCpks.cols();
    unsigned wanted = p.kc.sp_target * p.kc.sp_factor_pre_APL * double(cols);
    KCpks.transposeInPlace();
    KCpks.resize(1, KCpks.size());
    /* Choose a threshold for each KC by inspecting its sorted responses. */
    for (unsigned i = 0; i < p.kc.N; i++) {
        unsigned offset = i*cols;
        std::sort(KCpks.data()+offset, KCpks.data()+offset+cols,
                std::greater<double>());
        thr(i) += KCpks(offset+wanted);
    }
    return thr;
}
Column choose_KC_thresh_mixed(
        ModelParams const& p, Matrix& KCpks, Column const& spont_in) {
    /* Just average uniform and homeostatic thresholding. */
    // choose_KC_thresh_X methods mess with KCpks, so we have to give them each
    // their own.
    Matrix& KCpks1 = KCpks;
    Matrix KCpks2 = KCpks;
    Column uniform = choose_KC_thresh_uniform(p, KCpks1, spont_in);
    Column hstatic = choose_KC_thresh_homeostatic(p, KCpks2, spont_in);
    return (uniform+hstatic)/2.0;
}

void fit_sparseness(ModelParams const& p, RunVars& rv) {
    rv.log("fitting sparseness");

    std::vector<unsigned> tlist = p.kc.tune_from;
    if (!tlist.size()) {
        for (unsigned i = 0; i < get_nodors(p); i++) tlist.push_back(i);
    }
    rv.log(cat("wAPLKC mean: ", rv.kc.wAPLKC.mean()));
    unsigned num_claws = rv.kc.claw_to_kc.size();
    if(!p.kc.wPNKC_one_row_per_claw){
        rv.kc.wAPLKC.resize(p.kc.N,1);
        rv.kc.wKCAPL.resize(1,p.kc.N);
    }else {
        rv.log("wAPLKC resized to num_claws");
        rv.kc.wAPLKC.resize(num_claws,1);
        rv.kc.wKCAPL.resize(1,num_claws);
    }
    int wAPLKC_nan_count = 0; 
    // Check for NaN values in wAPLKC
    for (int i = 0; i < rv.kc.wAPLKC.rows(); ++i) {
        for (int j = 0; j < rv.kc.wAPLKC.cols(); ++j) {
            if (std::isnan(rv.kc.wAPLKC(i, j))) {
                wAPLKC_nan_count++; 
            }
        }
    }
    std::cout<< "Number of NaN found in wAPLKC: " << wAPLKC_nan_count << std::endl; 

    int wKCAPL_nan_count = 0; 
    // Check for NaN values in wKCAPL
    for (int i = 0; i < rv.kc.wKCAPL.rows(); ++i) {
        for (int j = 0; j < rv.kc.wKCAPL.cols(); ++j) {
            if (std::isnan(rv.kc.wKCAPL(i, j))) {
                wKCAPL_nan_count++;
            }
        }
    }
    std::cout<< "Number of NaN found in wAPLKC: " << wAPLKC_nan_count << std::endl; 

    std::cout << "wAPLKC size" << rv.kc.wAPLKC.size() << std::endl;
    std::cout << "wKCAPL szie" << rv.kc.wKCAPL.size() << std::endl;
    /* Calculate spontaneous input to KCs. */
    // TODO log stuff about PN spont to figure out if part of that isn't init'd
    // properly?

    // Hmm, I was wondering if this makes sense, if wPNKC is length of KC,
    // does it still make sense to calculate threshold using this matrix? 
    Column spont_in = rv.kc.wPNKC * sample_PN_spont(p, rv);
    rv.kc.spont_in = spont_in;

    Column wAPLKC_unscaled(p.kc.N, 1);
    Row wKCAPL_unscaled(1, p.kc.N);
    if(p.kc.wPNKC_one_row_per_claw){
        wAPLKC_unscaled.resize(num_claws, 1);
        wKCAPL_unscaled.resize(1, num_claws);
    }
    
    rv.log(cat("size wAPLKC_unscaled: ", wAPLKC_unscaled.size()));
    

    if (p.kc.preset_wAPLKC) {
        // TODO delete
        rv.log(cat("INITIAL rv.kc.wAPLKC.mean(): ", rv.kc.wAPLKC.mean()));

        // should be a deep copy
        wAPLKC_unscaled = rv.kc.wAPLKC;

        // TODO delete
        rv.log(cat("INITIAL wAPLKC_unscaled.mean(): ", wAPLKC_unscaled.mean()));
    }
    if (p.kc.preset_wKCAPL) {
        // TODO delete
        rv.log(cat("INITIAL rv.kc.wKCAPL.mean(): ", rv.kc.wKCAPL.mean()));

        wKCAPL_unscaled = rv.kc.wKCAPL;

        // TODO delete
        rv.log(cat("INITIAL wKCAPL_unscaled.mean(): ", wKCAPL_unscaled.mean()));
    }

    /* Set starting values for the things we'll tune. */
    // TODO matter? seems to be overwritten below in this case anyway...
    // (and put inside this conditional to avoid overwriting values set in python, via
    // pybind11)
    if (p.kc.tune_apl_weights) {
        if (!p.kc.preset_wAPLKC) {
            rv.kc.wAPLKC.setZero();
        }
        if (!p.kc.preset_wKCAPL) {
            rv.kc.wKCAPL.setConstant(1.0/float(p.kc.N));
        }
    }
    // TODO check that, in NOT p.kc.tune_apl_weights case, wAPLKC and wKCAPL are
    // appropriately initialized? maybe also in preset_wAPLKC/preset_wKCAPL = true
    // cases above?

    if (!p.kc.use_vector_thr) {
        if (!p.kc.use_fixed_thr) {
            rv.kc.thr.setConstant(1e5); // higher than will ever be reached
        }
        else {
            rv.log(cat("using FIXED threshold: ", p.kc.fixed_thr));
            // TODO would it ever make sense to have add_fixed_thr_to_spont=False?
            // when? in any cases i use? doc
            if (p.kc.add_fixed_thr_to_spont) {
                // TODO delete + replace w/ similar commented line below
                // (after confirming the 2 things w/ factor 2 cancel out...)
                rv.log("adding fixed threshold to 2 * spontaneous PN input to each KC");
                //rv.log("adding fixed threshold to spontaneous PN input to each KC");
                // TODO TODO what are units of spont_in? doc these as units of fixed_thr
                rv.kc.thr = p.kc.fixed_thr + spont_in.array()*2.0;
            } else {
                rv.kc.thr.setConstant(p.kc.fixed_thr);
            }
        }
    } else {
        rv.log("using prespecified vector KC thresholds");
        // TODO even want to allow `add_fixed_thr_to_spont = False`? don't think it's
        // useful now
        if (p.kc.add_fixed_thr_to_spont) {
            rv.log("adding threshold to 2 * spontaneous PN input to each KC");

            // TODO delete
            // TODO do i need .array() here? also, i assuming changing <x>.array() also
            // changes values in <x> (assuming it's a Matrix/similar)?
            rv.log(cat("(before adding spont) rv.kc.thr.mean(): ", rv.kc.thr.mean()));

            // TODO this line working as intended? (do need LHS .array() to avoid err,
            // at least w/ RHS as it is here)
            rv.kc.thr.array() += spont_in.array()*2.0;

            // TODO delete
            // TODO do i need .array() here?
            rv.log(cat("(after adding spont) rv.kc.thr.mean(): ", rv.kc.thr.mean()));
        }
    }

    /* Used for measuring KC voltage; defined here to make it shared across all
     * threads.*/
    Matrix KCpks(p.kc.N, tlist.size()); KCpks.setZero();

    /* Used to store odor response data during APL tuning. */
    Matrix KCmean_st(p.kc.N, 1+ ((tlist.size() - 1) / p.kc.apltune_subsample));
    // TODO TODO should this not be computed on first iteration?
    /* Used to store the current sparsity.
     * Initially set to the below value because, given default model
     * parameters, it causes tuning to complete in just one iteration. */
    double sp = 0.076;
    /* Used to count number of times looped; the 'learning rate' is decreased
     * as 1/sqrt(count) with each iteration. */
    rv.kc.tuning_iters = 0;

    unsigned const TTFIXED = 1;
    unsigned const TTHSTATIC = 2;
    unsigned const TTMIXED = 3;
    unsigned const TTUNIFORM = 4;
    unsigned const TTINVALID = 5;
    std::string tt = p.kc.thr_type;
    bool nott = (tt == "");
    unsigned thrtype =
        nott ?
            p.kc.use_fixed_thr ? TTFIXED :
            p.kc.use_homeostatic_thrs ? TTHSTATIC :
            TTUNIFORM
        :   tt == "uniform" ? TTUNIFORM :
            tt == "hstatic" ? TTHSTATIC :
            tt == "mixed" ? TTMIXED :
            tt == "fixed" ? TTFIXED :
        (abort(), TTINVALID);

    /* Break up into threads. */
#pragma omp parallel
    {
        /* Output matrices for the KC simulation. */
        Matrix Vm(p.kc.N, p.time.steps_all());
        rv.log(cat("sive of Vm: ", p.kc.N));
        Matrix spikes(p.kc.N, p.time.steps_all());
        Matrix nves(p.kc.N, p.time.steps_all());
        Row inh(1, p.time.steps_all());
        Row Is(1, p.time.steps_all());

        // TODO delete (assuming i want this for use_vector_thr. why don't i for
        // TTFIXED?)
        // if (thrtype != TTFIXED && !p.kc.use_vector_thr) {
        if (thrtype != TTFIXED && !p.kc.use_vector_thr) {
#pragma omp single
            {
                // TODO print str value for thrtype instead? (may need to add something
                // to invert mapping above. seems like some cases above currently don't
                // use the existing string p.kc.thr_type [but that could be changed?])
                rv.log(cat("choosing thresholds from spontaneous input (thrtype=",
                           thrtype, ")"));
            }

            // TODO TODO maybe i still want to sim_KC_layer in use_vector_thr case
            // (just not use it to pick a thr)?

            /* Measure voltages achieved by the KCs, and choose a threshold
             * based on that. */
#pragma omp for
            for (unsigned i = 0; i < tlist.size(); i++) {
                sim_KC_layer(p, rv,
                        rv.pn.sims[tlist[i]], rv.ffapl.vm_sims[tlist[i]],
                        Vm, spikes, nves, inh, Is);
#pragma omp critical
                KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*2.0;
            }

#pragma omp single
            {
                // TODO TODO need to redefine these after end of fit_sparseness
                // (so they are actually accurate and useful in mb_model's use to
                // compute per-subtype thresholds) (currently just hardcoding thresholds
                // rather than trying to compute them from pks in python)
                rv.kc.pks = KCpks;
                /*for (unsigned w = 0; w < rv.kc.pks.rows(); w++) {
                    for (unsigned z = 0; z < rv.kc.pks.cols(); z++) {
                        if (rv.kc.pks(w,z) < -1e20) abort();
                    }
                }*/

                // TODO TODO make a new variable, like rv.kc.pks, but only set at the
                // end (so as to also include the APL's influence). store the same peak
                // KC Vms (or whatever exact quantity pks is)? (same thing comment above
                // is asking for, just into a new variable)

                /* Finish picking thresholds. */
                rv.kc.thr =
                    (thrtype == TTHSTATIC ? choose_KC_thresh_homeostatic :
                     thrtype == TTMIXED ? choose_KC_thresh_mixed :
                     choose_KC_thresh_uniform)
                    (p, KCpks, spont_in);
                // TODO TODO compute + log sparsity here? (from KCpks)
                // TODO + save into new rv variable, for use in al_analysis?
                // (even worth? i assume that w/ reasonable pre-conditions, we can
                // always get pretty bang-on here?)
            }
        }

        // TODO if i move the stuff in this `#pragma omp single` block up enough, can i
        // avoid need to switch back to single threaded? (without it here,
        // `use_connectome_APL_weights=True` sensitivity analysis check repro-ing output
        // w/ fixed wAPLKC/wKCAPL is failing, b/c crazy high values on output
        // wAPLKC/etc)
#pragma omp single
        {
        rv.log("after first sim_KC_layer reached");
        if (!p.kc.tune_apl_weights && p.kc.preset_wAPLKC) {
            // TODO delete
            rv.log(cat("FIXED rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

            rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
        }
        if (!p.kc.tune_apl_weights && p.kc.preset_wKCAPL) {
            // TODO delete
            rv.log(cat("FIXED rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

            rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
        }
        }

        // TODO TODO in use_vector_thr=True case, want to at least log/save the
        // mean response rate before APL (esp if rv.kc.thr not set appropriately there,
        // which maybe could have been used in python to compute that?)

        // TODO if `!tune_apl_weights` just return here, so i can de-ident code below?
        // or does some or it need to run?
        /* Enter this region only if APL use is enabled; if disabled, just exit
         * (at this point APL->KC weights are set to 0). */
        if (p.kc.tune_apl_weights) {
#pragma omp single
        {
            rv.log(cat("tuning APL<->KC weights; tuning begin (",
                        "target=", p.kc.sp_target,
                        " acc=", p.kc.sp_acc,
                        ")"));

            rv.kc.tuning_iters = 1;
            // TODO maybe require/assume input preset vectors will be normalized or
            // scaled in a certain way? or compute appropriate w[APLKC|KCAPL]_scale
            // constants to have mean (after multiplying by preset vectors) equal to
            // what we would have been starting with before (maybe to average value of 1
            // [this is what al_analysis is currently doing], so we can set *_scale
            // factors to same as wAPLKC/wKCAPL being set below)?
            /* Starting values for to-be-tuned APL<->KC weights. */
            if (!p.kc.preset_wAPLKC) {
                // e.g. 3 w/ sp_target=0.1
                rv.kc.wAPLKC.setConstant(2*ceil(-log(p.kc.sp_target)));
            } else {
                rv.kc.wAPLKC_scale = 2*ceil(-log(p.kc.sp_target));
                // TODO delete
                rv.log(cat("INITIAL rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

                rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
            }
            if (!p.kc.preset_wKCAPL) {
                rv.kc.wKCAPL.setConstant(2*ceil(-log(p.kc.sp_target)) / double(p.kc.N));
            } else {
                rv.kc.wKCAPL_scale = 2*ceil(-log(p.kc.sp_target)) / double(p.kc.N);
                // TODO delete
                rv.log(cat("INITIAL rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

                rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
            }
            // TODO have code fail (terminate w/o achieving target sp) [or backtrack
            // somehow] if count of either changes (don't want to add 0s)
            int n_wAPLKC_lte0_initial = (rv.kc.wAPLKC.array() <= 0.0).count();
            int n_wKCAPL_lte0_initial = (rv.kc.wKCAPL.array() <= 0.0).count();
            rv.log(cat("n_wAPLKC_lte0_initial: ", n_wAPLKC_lte0_initial));
            rv.log(cat("n_wKCAPL_lte0_initial: ", n_wKCAPL_lte0_initial));
        }

        /* Continue tuning until we reach the desired sparsity. */
        do {
            //rv.log(cat("** t", omp_get_thread_num(), " @ top"));
#pragma omp barrier

#pragma omp single
            {
                /* Modify the APL<->KC weights in order to move in the
                 * direction of the target sparsity. */
                double lr = p.kc.sp_lr_coeff / sqrt(double(rv.kc.tuning_iters));
                double delta = (sp - p.kc.sp_target) * lr / p.kc.sp_target;
                // TODO log initial value of delta?

                if (!p.kc.preset_wAPLKC) {
                    // TODO why using .array() for +=, but not for direct assignment
                    // operations? is .array() actually necessary in this case?
                    // what does .array() do?
                    rv.kc.wAPLKC.array() += delta;
                } else {
                    rv.kc.wAPLKC_scale += delta;

                    // TODO delete?
                    rv.log(cat("rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

                    rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
                }

                if (!p.kc.preset_wKCAPL) {
                    rv.kc.wKCAPL.array() += delta / double(p.kc.N);
                } else {
                    rv.kc.wKCAPL_scale += delta / double(p.kc.N);

                    // TODO delete?
                    rv.log(cat("rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

                    rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
                }

                // TODO TODO probably want to abort (so we can change tuning params and
                // re-run) rather than clip values (which would break overall shape of
                // vector(s) from connectome). or otherwise take steps to avoid this
                // state (would probably be better if we didn't have to abort).
                // (could give people a message to choose different step size param)
                /* If we learn too fast in the negative direction we could end
                 * up with negative weights. */
                if (delta < 0.0) {
                    if (!p.kc.preset_wAPLKC) {
                        int n_wAPLKC_lt0 = (rv.kc.wAPLKC.array() < 0.0).count();
                        rv.log(cat("n_wAPLKC_lt0: ", n_wAPLKC_lt0));

                        // TODO TODO at least log that this is happening (doesn't
                        // already mean we have any negative weights, just b/c we are in
                        // this block tho... would need to know if there are any < 0)?
                        rv.kc.wAPLKC = (rv.kc.wAPLKC.array() < 0.0).select(
                                0.0, rv.kc.wAPLKC);
                    }

                    if (!p.kc.preset_wKCAPL) {
                        int n_wKCAPL_lt0 = (rv.kc.wKCAPL.array() < 0.0).count();
                        rv.log(cat("n_wKCAPL_lt0: ", n_wKCAPL_lt0));

                        rv.kc.wKCAPL = (rv.kc.wKCAPL.array() < 0.0).select(
                                0.0, rv.kc.wKCAPL);
                    }
                }

                rv.log(cat( "* i=", rv.kc.tuning_iters,
                            ", sp=", sp,
                            ", wAPLKC_delta=", delta,
                            ", lr=", lr));

                // TODO delete
                // for debugging + trying to support scaling of arbitrary positive
                // vector wAPLKC/wKCAPL inputs
                if (p.kc.preset_wAPLKC) {
                    double wAPLKC_mean = rv.kc.wAPLKC.mean();
                    // TODO if keeping, try to combine w/  previous .log call above?
                    rv.log(cat("wAPLKC_mean: ", wAPLKC_mean));
                }
                if (p.kc.preset_wKCAPL) {
                    double wKCAPL_mean = rv.kc.wKCAPL.mean();
                    // TODO if keeping, try to combine w/  previous .log call above?
                    rv.log(cat("wKCAPL_mean: ", wKCAPL_mean));
                }
                //

                rv.kc.tuning_iters++;
            }

            //rv.log(cat("** t", omp_get_thread_num(), " @ before testing"));
            /* Run through a bunch of odors to test sparsity. */
#pragma omp for
            for (unsigned i = 0; i < tlist.size(); i+=p.kc.apltune_subsample) {
                sim_KC_layer(p, rv,
                        rv.pn.sims[tlist[i]], rv.ffapl.vm_sims[tlist[i]],
                        Vm, spikes, nves, inh, Is);
                KCmean_st.col(i / p.kc.apltune_subsample) = spikes.rowwise().sum();

//#pragma omp critical
                // TODO delete?
                ////KCpks.col(i) = Vm.rowwise().maxCoeff(); // - spont_in*2.0;
                // TODO probably restore
                //KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*2.0;
                ////KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*10.0;
            }
            //rv.log(cat("** t", omp_get_thread_num(), " @ after testing"));

#pragma omp single
            {
                // TODO delete
                //rv.log(cat("KCpks.mean(): ", KCpks.mean()));
                //rv.log(cat("spont_in.mean(): ", spont_in.mean()));
                //
                // TODO restore? (+ fix surrounding) (or probably better set, set
                // post-APL peaks into new rv.kc variable...)
                // don't think i could use same way as i do for prior pks [which I use
                // in python to set thresholds, in a similar manner to how they are used
                // in here] tho, so might be pointless.
                // more complicated by this point, since also depend on activity of all
                // other KCs, so don't think i can as easily use to set e.g. a single
                // KC's APL weights.
                //rv.kc.pks = KCpks;

                KCmean_st = (KCmean_st.array() > 0.0).select(1.0, KCmean_st);
                sp = KCmean_st.mean();
            }

            // TODO TODO why have multiple threads each printing these, if always the
            // same across each (actually true? indicate a bug?)
            rv.log(cat("** t", omp_get_thread_num(), " @ before bottom cond [",
                        "sp=", sp, 
                        ", i=", rv.kc.tuning_iters,
                        ", tgt=", p.kc.sp_target,
                        ", acc=", p.kc.sp_acc,
                        ", I=", p.kc.max_iters,
                        "]"));
        } while ((abs(sp - p.kc.sp_target) > (p.kc.sp_acc * p.kc.sp_target))
                && (rv.kc.tuning_iters <= p.kc.max_iters));
        //rv.log(cat("** t", omp_get_thread_num(), " @ exit"));
#pragma omp barrier
#pragma omp single
        {
            rv.kc.tuning_iters--;
        }
    }}
    // TODO delete?
    rv.log(cat("FINAL rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));
    rv.log(cat("FINAL rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

    // TODO always log tuned parameters at end (fixed_thr, wAPLKC/wKCAPL when not
    // preset, or wAPLKC_scale/wKCAPL_scale when preset)
    rv.log("done fitting sparseness");
}


void fit_sparseness_claw(ModelParams const& p, RunVars& rv) {
    rv.log("test fit_sparseness_claw");

    std::vector<unsigned> tlist = p.kc.tune_from;
    if (!tlist.size()) {
        for (unsigned i = 0; i < get_nodors(p); i++) tlist.push_back(i);
    }

    /* Calculate spontaneous input to KCs. */
    // TODO log stuff about PN spont to figure out if part of that isn't init'd
    // properly?
    Column spont_in = rv.kc.wPNKC * sample_PN_spont(p, rv);
    rv.kc.spont_in = spont_in;

    
    // declare wAPLKC and wKCAPL with size of claws instead of number of KCs
    unsigned num_claws = rv.kc.claw_to_kc.size();
    rv.log(cat("number of claws: ", num_claws)); // claw number is correct 
    // BEFORE any resize, capture the preset vectors if present
    Column preset_wAPLKC_KC;   // expected shape: (p.kc.N, 1) if per-KC
    Row    preset_wKCAPL_KC;   // expected shape: (1, p.kc.N)
    if (p.kc.preset_wAPLKC) {
        preset_wAPLKC_KC = rv.kc.wAPLKC;   // deep copy of whatever Python set
    }
    if (p.kc.preset_wKCAPL) {
        preset_wKCAPL_KC = rv.kc.wKCAPL;   // deep copy
    }
    rv.log(cat("preset_wAPLKC_KC mean: ", preset_wAPLKC_KC.mean()));

    // Now resize claw-wise containers and ZERO them to avoid UB
    rv.kc.wAPLKC.resize(num_claws, 1);
    rv.kc.wAPLKC.setZero();
    rv.kc.wKCAPL.resize(1, num_claws);
    rv.kc.wKCAPL.setZero();

    // Build unscaled per-CLAW presets deterministically
    Column wAPLKC_unscaled(num_claws, 1); wAPLKC_unscaled.setOnes();  // default 1s
    Row    wKCAPL_unscaled(1, num_claws); wKCAPL_unscaled.setOnes();

    
    if (p.kc.preset_wAPLKC) {
        // If the preset was per-KC length N, expand to claws using claw_to_kc
        if (preset_wAPLKC_KC.rows() == (Eigen::Index)p.kc.N && preset_wAPLKC_KC.cols() == 1) { // we actually don't need this branch? 
            for (unsigned claw = 0; claw < num_claws; ++claw) {
                unsigned kc = rv.kc.claw_to_kc[claw];
                wAPLKC_unscaled(claw, 0) = preset_wAPLKC_KC(kc, 0);
            }
        } else if (preset_wAPLKC_KC.rows() == (Eigen::Index)num_claws && preset_wAPLKC_KC.cols() == 1) {
            // already per-claw
            wAPLKC_unscaled = preset_wAPLKC_KC;
        } else {
            rv.log("ERROR: preset_wAPLKC has unexpected shape; falling back to ones.");
        }
    }

    if (p.kc.preset_wKCAPL) {
        if (preset_wKCAPL_KC.rows() == 1 && preset_wKCAPL_KC.cols() == (Eigen::Index)p.kc.N) {
            for (unsigned claw = 0; claw < num_claws; ++claw) {
                unsigned kc = rv.kc.claw_to_kc[claw];
                wKCAPL_unscaled(0, claw) = preset_wKCAPL_KC(0, kc);
            }
        } else if (preset_wKCAPL_KC.rows() == 1 && preset_wKCAPL_KC.cols() == (Eigen::Index)num_claws) {
            wKCAPL_unscaled = preset_wKCAPL_KC;
        } else {
            rv.log("ERROR: preset_wKCAPL has unexpected shape; falling back to ones.");
        }
    }
    rv.log(cat("wAPLKC_unscaled mean: ", wAPLKC_unscaled.mean()));
    // TODO do i actually need these vars? don't i still want to assign scaled
    // wAPLKC/wKCAPL vectors into rv.kc.wAPLKC/wKCAPL at the end
    /* Should only be used in preset_w[APLKC|KCAPL] = true cases */
    

    /* Set starting values for the things we'll tune. */
    // TODO matter? seems to be overwritten below in this case anyway...
    // (and put inside this conditional to avoid overwriting values set in python, via
    // pybind11)
    if (p.kc.tune_apl_weights) {
        if (!p.kc.preset_wAPLKC) {
            rv.kc.wAPLKC.setZero();
        }
        if (!p.kc.preset_wKCAPL) {
            rv.kc.wKCAPL.setConstant(1.0/float(num_claws));
        }
    }

    // print tests: 
    {
        std::ostringstream oss;
        oss << "test after zero: first 10 wAPLKC values: ";
        for (int i = 0; i < std::min<int>(10, rv.kc.wAPLKC.size()); ++i) {
            oss << rv.kc.wAPLKC(i) << " ";
        }
        rv.log(oss.str());
    }

    {
        std::ostringstream oss;
        oss << "test after zero: first 10 wKCAPL values: ";
        for (int i = 0; i < std::min<int>(10, rv.kc.wKCAPL.size()); ++i) {
            oss << rv.kc.wKCAPL(i) << " ";
        }
        rv.log(oss.str());
    }

    // TODO check that, in NOT p.kc.tune_apl_weights case, wAPLKC and wKCAPL are
    // appropriately initialized? maybe also in preset_wAPLKC/preset_wKCAPL = true
    // cases above?

    if (!p.kc.use_vector_thr) {
        if (!p.kc.use_fixed_thr) {
            rv.kc.thr.setConstant(1e5); // higher than will ever be reached
        }
        else {
            rv.log(cat("using FIXED threshold: ", p.kc.fixed_thr));
            // TODO would it ever make sense to have add_fixed_thr_to_spont=False?
            // when? in any cases i use? doc
            if (p.kc.add_fixed_thr_to_spont) {
                // TODO delete + replace w/ similar commented line below
                // (after confirming the 2 things w/ factor 2 cancel out...)
                rv.log("adding fixed threshold to 2 * spontaneous PN input to each KC");
                //rv.log("adding fixed threshold to spontaneous PN input to each KC");
                // TODO TODO what are units of spont_in? doc these as units of fixed_thr
                rv.kc.thr = p.kc.fixed_thr + spont_in.array()*2.0;
            } else {
                rv.kc.thr.setConstant(p.kc.fixed_thr);
            }
        }
    } else {
        rv.log("using prespecified vector KC thresholds");
        // TODO even want to allow `add_fixed_thr_to_spont = False`? don't think it's
        // useful now
        if (p.kc.add_fixed_thr_to_spont) {
            rv.log("adding threshold to 2 * spontaneous PN input to each KC");

            // TODO delete
            // TODO do i need .array() here? also, i assuming changing <x>.array() also
            // changes values in <x> (assuming it's a Matrix/similar)?
            rv.log(cat("(before adding spont) rv.kc.thr.mean(): ", rv.kc.thr.mean()));

            // TODO this line working as intended? (do need LHS .array() to avoid err,
            // at least w/ RHS as it is here)
            rv.kc.thr.array() += spont_in.array()*2.0;

            // TODO delete
            // TODO do i need .array() here?
            rv.log(cat("(after adding spont) rv.kc.thr.mean(): ", rv.kc.thr.mean()));
        }
    }
    rv.log("passed the p.kc.use_vector_thr thing");
    /* Used for measuring KC voltage; defined here to make it shared across all
     * threads.*/
    Matrix KCpks(p.kc.N, tlist.size()); KCpks.setZero();
    /* Used to store odor response data during APL tuning. */
    Matrix KCmean_st(p.kc.N, 1+ ((tlist.size() - 1) / p.kc.apltune_subsample));
    // TODO TODO should this not be computed on first iteration?
    /* Used to store the current sparsity.
     * Initially set to the below value because, given default model
     * parameters, it causes tuning to complete in just one iteration. */
    double sp = 0.0789;
    /* Used to count number of times looped; the 'learning rate' is decreased
     * as 1/sqrt(count) with each iteration. */
    rv.kc.tuning_iters = 0;

    // how the f? is there something wrong with this line of code; 
    int claw_compartment_size = rv.kc.claw_compartments.size();
    rv.log(cat("claw_compartment_size: ", claw_compartment_size));
    int n_compartments = rv.kc.claw_compartments.maxCoeff() + 1;
    rv.log("passed some initialization steps");

    // TO BE REVIEWED
    // Map each KC to the set of compartments it has claws in
    // compartment_claws; for each compartment, it has the index of claws that it contains?
     
    // Initialize per-compartment APL↔KC weight scalars
    // std::vector<double> wAPLKC_scales(n_compartments, 2 * ceil(-log(p.kc.sp_target)));
    // std::vector<double> wKCAPL_scales(n_compartments, 2 * ceil(-log(p.kc.sp_target)) / double(p.kc.N));

    // Try sth new, differentially initializes the weight for different compartments
    // TO BE REVIEWED
    std::vector<double> wAPLKC_scales(n_compartments);
    std::vector<double> wKCAPL_scales(n_compartments);
    for (int comp = 0; comp < n_compartments; ++comp) {
        double base = 2 * ceil(-log(p.kc.sp_target));
        // file-local or function-static; not in a parallel block
        static std::mt19937 rng(123456);
        std::uniform_real_distribution<double> U(0.0, 1.0);
        double jitter = 0.1 * base * U(rng);
        wAPLKC_scales[comp] = base + jitter;
        wKCAPL_scales[comp] = (base + jitter) / double(num_claws); 
    }
    rv.log("passed the wAPLKC_scales initialization");
    // TO BE REVIEWED
    // Apply initial compartment-specific weights into the full claw-wise vectors
    // Problem probability happened here; wAPLKC may not be decalred to the size of claws. 
    for (unsigned claw = 0; claw < num_claws; ++claw) {
        int comp = rv.kc.claw_compartments(claw);
        rv.kc.wAPLKC(claw, 0) = wAPLKC_scales[comp];
        rv.kc.wKCAPL(0, claw) = wKCAPL_scales[comp];
    }
    rv.log("passed the wAPLKC initialization");
    std::vector<std::vector<int>> compartment_claws(n_compartments);
    for (unsigned claw = 0; claw < num_claws; ++claw) {
        int comp = rv.kc.claw_compartments(claw);
        if (0 <= comp && comp < n_compartments) {
            compartment_claws[comp].push_back(claw);
        } else {
            // optional: log or assert
        }
    }


    // print tests: 
    {
        std::ostringstream oss;
        oss << "test after initialization: first 10 wAPLKC values: ";
        for (int i = 0; i < std::min<int>(10, rv.kc.wAPLKC.size()); ++i) {
            oss << rv.kc.wAPLKC(i) << " ";
        }
        rv.log(oss.str());
    }

    {
        std::ostringstream oss;
        oss << "test after initialization: first 10 wKCAPL values: ";
        for (int i = 0; i < std::min<int>(10, rv.kc.wKCAPL.size()); ++i) {
            oss << rv.kc.wKCAPL(i) << " ";
        }
        rv.log(oss.str());
    }

    std::vector<int> comp_claw_count(n_compartments, 0);
    for (Eigen::Index claw = 0; claw < rv.kc.claw_to_kc.size(); ++claw) {
        int comp = rv.kc.claw_compartments(claw);
        if (comp >= 0 && comp < n_compartments) comp_claw_count[comp]++;
    }
    //printf("comp_claw_count[0] = %d\n", comp_claw_count[0]);
    //printf("comp_claw_count[1] = %d\n", comp_claw_count[1]);
    //int n_compartments = rv.kc.claw_compartments.maxCoeff() + 1;

    // // Map each KC to its compartments:
    // std::vector<std::unordered_set<int>> kc_to_compartments(p.kc.N);
    // for (Eigen::Index claw = 0; claw < rv.kc.claw_to_kc.size(); ++claw) {
    //     unsigned kc = rv.kc.claw_to_kc[claw];
    //     int comp    = rv.kc.claw_compartments(claw);
    //     if (0 <= comp && comp < n_compartments) {
    //         kc_to_compartments[kc].insert(comp);
    //     } else {
    //         assert(false && "claw_compartments out of range");
    //     }
    // }
    // // TO BE REVIEWED
    // std::vector<std::vector<int>> compartment_kcs(n_compartments);
    // for (unsigned kc = 0; kc < p.kc.N; ++kc) {
    //     if (!kc_to_compartments[kc].empty()) {
    //         int comp = *kc_to_compartments[kc].begin();
    //         compartment_kcs[comp].push_back(kc);
    //     }  // assume one compartment per KC for now 
    // }

    // std::vector<std::vector<int>> compartment_kcs(n_compartments);
    // for (unsigned kc = 0; kc < p.kc.N; ++kc) {
    //     const auto& comps = kc_to_compartments[kc];
    //     if (!comps.empty()) {
    //         int chosen = *std::min_element(comps.begin(), comps.end()); // stable rule
    //         compartment_kcs[chosen].push_back(kc);
    //     }
    // }
    // // (optional) sort for a stable KC order inside each compartment:
    // for (auto& v : compartment_kcs) std::sort(v.begin(), v.end());



    unsigned const TTFIXED = 1;
    unsigned const TTHSTATIC = 2;
    unsigned const TTMIXED = 3;
    unsigned const TTUNIFORM = 4;
    unsigned const TTINVALID = 5;
    std::string tt = p.kc.thr_type;
    bool nott = (tt == "");
    unsigned thrtype =
        nott ?
            p.kc.use_fixed_thr ? TTFIXED :
            p.kc.use_homeostatic_thrs ? TTHSTATIC :
            TTUNIFORM
        :   tt == "uniform" ? TTUNIFORM :
            tt == "hstatic" ? TTHSTATIC :
            tt == "mixed" ? TTMIXED :
            tt == "fixed" ? TTFIXED :
        (abort(), TTINVALID);

    // stores the current measured sparsity (activity level) of Kenyon Cells (KCs) in each compartment
    // used to adjust the inhibitory APL↔KC weights during the tuning loop to bring sparsity closer to a target.
    std::vector<double> comp_sparsities(n_compartments, 0.0);

    /* Break up into threads. */
#pragma omp parallel
    {
        /* Output matrices for the KC simulation. */
        Matrix Vm(p.kc.N, p.time.steps_all());
        Matrix spikes(p.kc.N, p.time.steps_all());
        Matrix nves(p.kc.N, p.time.steps_all());
        Matrix inh(n_compartments, p.time.steps_all());
        Matrix Is (n_compartments, p.time.steps_all());

        // TODO delete (assuming i want this for use_vector_thr. why don't i for
        // TTFIXED?)
        // if (thrtype != TTFIXED && !p.kc.use_vector_thr) {

        // print tests: 
        // {
        //     std::ostringstream oss;
        //     oss << "test before sim_KC_layer: first 10 wAPLKC values: ";
        //     for (int i = 0; i < std::min<int>(10, rv.kc.wAPLKC.size()); ++i) {
        //         oss << rv.kc.wAPLKC(i) << " ";
        //     }
        //     rv.log(oss.str());
        // }

        // {
        //     std::ostringstream oss;
        //     oss << "test before sim_KC_layer: first 10 wKCAPL values: ";
        //     for (int i = 0; i < std::min<int>(10, rv.kc.wKCAPL.size()); ++i) {
        //         oss << rv.kc.wKCAPL(i) << " ";
        //     }
        //     rv.log(oss.str());
        // }

        if (thrtype != TTFIXED && !p.kc.use_vector_thr) {
#pragma omp single
            {
                // TODO print str value for thrtype instead? (may need to add something
                // to invert mapping above. seems like some cases above currently don't
                // use the existing string p.kc.thr_type [but that could be changed?])
                rv.log(cat("choosing thresholds from spontaneous input (thrtype=",
                           thrtype, ")"));
            }

            // TODO TODO maybe i still want to sim_KC_layer in use_vector_thr case
            // (just not use it to v pick a thr)?

            /* Measure voltages achieved by the KCs, and choose a threshold
             * based on that. */
#pragma omp for
            for (unsigned i = 0; i < tlist.size(); i++) {
                sim_KC_layer(p, rv,
                        rv.pn.sims[tlist[i]], rv.ffapl.vm_sims[tlist[i]],
                        Vm, spikes, nves, inh, Is);
#pragma omp critical
                KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*2.0;
            }

#pragma omp single
            {
                // TODO TODO need to redefine these after end of fit_sparseness
                // (so they are actually accurate and useful in mb_model's use to
                // compute per-subtype thresholds) (currently just hardcoding thresholds
                // rather than trying to compute them from pks in python)
                rv.kc.pks = KCpks;
                /*for (unsigned w = 0; w < rv.kc.pks.rows(); w++) {
                    for (unsigned z = 0; z < rv.kc.pks.cols(); z++) {
                        if (rv.kc.pks(w,z) < -1e20) abort();
                    }
                }*/

                // TODO TODO make a new variable, like rv.kc.pks, but only set at the
                // end (so as to also include the APL's influence). store the same peak
                // KC Vms (or whatever exact quantity pks is)? (same thing comment above
                // is asking for, just into a new variable)

                /* Finish picking thresholds. */
                rv.kc.thr =
                    (thrtype == TTHSTATIC ? choose_KC_thresh_homeostatic :
                     thrtype == TTMIXED ? choose_KC_thresh_mixed :
                     choose_KC_thresh_uniform)
                    (p, KCpks, spont_in);
                // TODO TODO compute + log sparsity here? (from KCpks)
                // TODO + save into new rv variable, for use in al_analysis?
                // (even worth? i assume that w/ reasonable pre-conditions, we can
                // always get pretty bang-on here?)
            }
        }

        // TODO if i move the stuff in this `#pragma omp single` block up enough, can i
        // avoid need to switch back to single threaded? (without it here,
        // `use_connectome_APL_weights=True` sensitivity analysis check repro-ing output
        // w/ fixed wAPLKC/wKCAPL is failing, b/c crazy high values on output
        // wAPLKC/etc)
#pragma omp single
        {
        if (!p.kc.tune_apl_weights && p.kc.preset_wAPLKC) {
            // TODO delete
            rv.log(cat("FIXED rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

            rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
        }
        if (!p.kc.tune_apl_weights && p.kc.preset_wKCAPL) {
            // TODO delete
            rv.log(cat("FIXED rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

            rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
        }
        }

        // TODO TODO in use_vector_thr=True case, want to at least log/save the
        // mean response rate before APL (esp if rv.kc.thr not set appropriately there,
        // which maybe could have been used in python to compute that?)

        // TODO if `!tune_apl_weights` just return here, so i can de-ident code below?
        // or does some or it need to run?
        /* Enter this region only if APL use is enabled; if disabled, just exit
         * (at this point APL->KC weights are set to 0). */
        if (p.kc.tune_apl_weights) {
#pragma omp single
        {
            rv.log(cat("tuning APL<->KC weights; tuning begin (",
                        "target=", p.kc.sp_target,
                        " acc=", p.kc.sp_acc,
                        ")"));

            rv.kc.tuning_iters = 1;
            // TODO maybe require/assume input preset vectors will be normalized or
            // scaled in a certain way? or compute appropriate w[APLKC|KCAPL]_scale
            // constants to have mean (after multiplying by preset vectors) equal to
            // what we would have been starting with before (maybe to average value of 1
            // [this is what al_analysis is currently doing], so we can set *_scale
            // factors to same as wAPLKC/wKCAPL being set below)?
            /* Starting values for to-be-tuned APL<->KC weights. */
            if (!p.kc.preset_wAPLKC) {
                // e.g. 3 w/ sp_target=0.1
                rv.kc.wAPLKC.setConstant(2*ceil(-log(p.kc.sp_target)));
            } else {
                rv.kc.wAPLKC_scale = 2*ceil(-log(p.kc.sp_target));
                // TODO delete
                rv.log(cat("INITIAL rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

                rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
            }
            if (!p.kc.preset_wKCAPL) {
                rv.kc.wKCAPL.setConstant(2*ceil(-log(p.kc.sp_target)) / double(num_claws)); // to be honest, should this be divide by num_claw per compartment? 
            } else {
                rv.kc.wKCAPL_scale = 2*ceil(-log(p.kc.sp_target)) / double(num_claws);
                // TODO delete
                rv.log(cat("INITIAL rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

                rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
            }
            // TODO TODO have code fail (terminate w/o achieving target sp) [or
            // backtrack somehow] if count of either changes (don't want to add 0s)
            int n_wAPLKC_lte0_initial = (rv.kc.wAPLKC.array() <= 0.0).count();
            int n_wKCAPL_lte0_initial = (rv.kc.wKCAPL.array() <= 0.0).count();
            rv.log(cat("n_wAPLKC_lte0_initial: ", n_wAPLKC_lte0_initial));
            rv.log(cat("n_wKCAPL_lte0_initial: ", n_wKCAPL_lte0_initial));
            // rv.kc.wAPLKC.setConstant(4.15e-315);
            // rv.kc.wKCAPL.setConstant(4.15e-318);
            // print tests: 
            rv.log(cat("wAPLKC_unscaled mean: ", wAPLKC_unscaled.mean()));
            {
                std::ostringstream oss;
                oss << "test after compare: first 10 wAPLKC values: ";
                for (int i = 0; i < std::min<int>(10, rv.kc.wAPLKC.size()); ++i) {
                    oss << rv.kc.wAPLKC(i) << " ";
                }
                rv.log(oss.str());
            }

            {
                std::ostringstream oss;
                oss << "test after compare: first 10 wKCAPL values: ";
                for (int i = 0; i < std::min<int>(10, rv.kc.wKCAPL.size()); ++i) {
                    oss << rv.kc.wKCAPL(i) << " ";
                }
                rv.log(oss.str());
            }
            rv.log(cat("test after compare wAPLKC: ", rv.kc.wAPLKC.mean()));
            rv.log(cat("test after compare wKCAPL: ", rv.kc.wKCAPL.mean()));
            rv.log(cat("threshold mean: ", rv.kc.thr.mean()));



        }
        

        std::vector<bool> converged(n_compartments, false);
        /* Continue tuning until we reach the desired sparsity. */
        while(true) { // the tuning loop! 
            //rv.log(cat("** t", omp_get_thread_num(), " @ top"));
            KCmean_st.setZero(); // FOR SPARSITY CHECK
            // std::fill(comp_sparsities.begin(), comp_sparsities.end(), 0.0); // FOR SPARSITY CHECK

#pragma omp barrier

#pragma omp for
            for (unsigned i = 0; i < tlist.size(); i+=p.kc.apltune_subsample) {
                sim_KC_layer(p, rv,
                        rv.pn.sims[tlist[i]], rv.ffapl.vm_sims[tlist[i]],
                        Vm, spikes, nves, inh, Is);
                KCmean_st.col(i / p.kc.apltune_subsample)  = spikes.rowwise().sum();

//#pragma omp critical
                // TODO delete?
                ////KCpks.col(i) = Vm.rowwise().maxCoeff(); // - spont_in*2.0;
                // TODO probably restore
                //KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*2.0;
                ////KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*10.0;
            }

#pragma omp single
            {
                /* Modify the APL<->KC weights in order to move in the
                 * direction of the target sparsity. */

                //double lr = p.kc.sp_lr_coeff / (1.0 + double(rv.kc.tuning_iters)); // CHECK
                double lr = p.kc.sp_lr_coeff_cl / sqrt(double(rv.kc.tuning_iters)); 

                

                // Compute per-compartment sparsities 
                // TO BE REVIEWED
                // Binarize all KC responses to 0/1
                KCmean_st = (KCmean_st.array() > 0.0).cast<double>();


                // Then compute each compartment’s sparsity
                // for (int comp = 0; comp < n_compartments; ++comp) {
                //     double sum = 0.0;
                //     for (int kc : compartment_kcs[comp]) {
                //         // Now row(kc).mean() is the fraction of odors in which KC 'kc' fired
                //         sum += KCmean_st.row(kc).mean();
                //     }
                //     comp_sparsities[comp] = sum / compartment_kcs[comp].size();
                // }
                // calculate sparsity using claw instead of KCs  
                std::vector<double> claw_active_counts(n_compartments, 0.0);
                const unsigned nCols = KCmean_st.cols();
                rv.log(cat("KCmean_st.cols: ", nCols));
                rv.log(cat("KCmean_st.rows: ", KCmean_st.rows()));
                for (int comp = 0; comp < n_compartments; ++comp) {
                    double sum_active = 0.0;

                    // iterate claws that belong to this compartment
                    for (int claw : compartment_claws[comp]) {
                        unsigned kc = rv.kc.claw_to_kc[claw];  // parent KC
                        // row(kc).sum() counts how many odors this KC fired for (because KCmean_st is 0/1)
                        sum_active += KCmean_st.row(kc).sum();
                    }
 
                    // normalize by number of claws and #odors considered
                    const double denom = std::max<size_t>(1, compartment_claws[comp].size()) * double(nCols);
                    claw_active_counts[comp] = sum_active;
                    comp_sparsities[comp]    = sum_active / denom;  // <-- claw-defined sparsity
                }
                

                // Update scalars for each compartment
                // TO BE REVIEWED
                // Per-compartment delta method
                for (int comp = 0; comp < n_compartments; ++comp) {
                    if (converged[comp]) continue;

                    double delta = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;

                    // Apply the update based on the preset flag
                    if (!p.kc.preset_wAPLKC) {
                        // Existing logic for updating individual scales
                        double delta_apl_kc = delta;
                        double delta_kc_apl = delta / std::max(1, comp_claw_count[comp]);
                        wAPLKC_scales[comp] += delta_apl_kc;
                        wKCAPL_scales[comp] += delta_kc_apl;
                    } else {
                        // Multi-compartment scaling method
                        wAPLKC_scales[comp] += delta;
                        // rv.log(cat("rv.kc.wAPLKC_scale_comp", comp, ": ", wAPLKC_scales[comp]));
                    }
                }

                // Push updated scalars into rv.kc weight vectors
                for (unsigned claw = 0; claw < num_claws; ++claw) {
                    int comp = rv.kc.claw_compartments(claw);
                    assert(0 <= comp && comp < n_compartments);

                    // Apply the scaling method based on the preset flag
                    if (!p.kc.preset_wAPLKC) {
                        rv.kc.wAPLKC(claw, 0) = wAPLKC_scales[comp];
                    } else {
                        // Use the scale from the corresponding compartment
                        // to scale the unscaled weights
                        rv.kc.wAPLKC(claw, 0) = wAPLKC_scales[comp] * wAPLKC_unscaled(claw, 0);
                    }
                    
                    // Note: The logic for wKCAPL will be similar if you also have a preset flag for it
                    if (!p.kc.preset_wKCAPL) {
                        rv.kc.wKCAPL(0, claw) = wKCAPL_scales[comp];
                    } else {
                        rv.kc.wKCAPL(0, claw) = wKCAPL_scales[comp] * wKCAPL_unscaled(0, claw);
                    }
                }
                // for (int comp = 0; comp < n_compartments; ++comp) {
                //     /* single delta method 
                //     double delta = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;

                //     wAPLKC_scales[comp] += delta;
                //     wKCAPL_scales[comp] += delta / double(p.kc.N);
                //     */
                    
                //     // per compartmental delta method
                //     if (converged[comp]) continue;

                //     double delta = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;
                //     double delta_apl_kc = delta;
                    
                //     // divide by number of claws in that compartment? 
                //     double delta_kc_apl = delta / std::max(1, comp_claw_count[comp]);
                //     if (!p.kc.preset_wAPLKC){
                //         wAPLKC_scales[comp] += delta
                //     } else {
                //         rv.log(cat("rv.kc.wAPLKC_scale ", rv.kc.wAPLKC_scale));
                        
                //     }
                    
                //     wAPLKC_scales[comp] += delta_apl_kc;
                //     wKCAPL_scales[comp] += delta_kc_apl;
                // }

                // Push updated scalars into rv.kc weight vectors
                for (unsigned claw = 0; claw < num_claws; ++claw) {
                    int comp = rv.kc.claw_compartments(claw);
                    assert(0 <= comp && comp < n_compartments);
                    rv.kc.wAPLKC(claw, 0) = wAPLKC_scales[comp];
                    rv.kc.wKCAPL(0, claw) = wKCAPL_scales[comp];
                }
                // for (int comp = 0; comp < n_compartments; ++comp) {
                //     if (converged[comp]) continue;

                //     double delta = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;

                //     // ---- APL→KC update ----
                //     if (!p.kc.preset_wAPLKC) {
                //         // Update each KC/claw in this compartment directly
                //         for (unsigned idx : compartment_kcs[comp]) {
                //             rv.kc.wAPLKC(idx, 0) += delta;  
                //         }
                //     } else {
                //         // Scale factor update
                //         wAPLKC_scales[comp] += delta;
                //         rv.log(cat("Comp ", comp, " wAPLKC_scale: ", wAPLKC_scales[comp]));
                //         for (unsigned idx : compartment_kcs[comp]) {
                //             rv.kc.wAPLKC(idx, 0) = wAPLKC_scales[comp] * wAPLKC_unscaled(idx, 0);
                //         }
                //     }

                //     // ---- KC→APL update ----
                //     double delta_kc_apl = delta / std::max<size_t>(1, compartment_kcs[comp].size());
                //     if (!p.kc.preset_wKCAPL) {
                //         for (unsigned idx : compartment_kcs[comp]) {
                //             rv.kc.wKCAPL(0, idx) += delta_kc_apl;
                //         }
                //     } else {
                //         wKCAPL_scales[comp] += delta_kc_apl;
                //         rv.log(cat("Comp ", comp, " wKCAPL_scale: ", wKCAPL_scales[comp]));
                //         for (unsigned idx : compartment_kcs[comp]) {
                //             rv.kc.wKCAPL(0, idx) = wKCAPL_scales[comp] * wKCAPL_unscaled(0, idx);
                //         }
                //     }
                // }

                



                /*per compartmental delta method*/
                rv.log(cat("number of compartments: ", n_compartments));
                rv.log(cat("* i=", rv.kc.tuning_iters, ", lr=", lr));
                for (int comp = 0; comp < n_compartments; ++comp) {
                    double delta_A = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;
                    double delta_K = delta_A / std::max(1, comp_claw_count[comp]);
                    std::ostringstream comp_s;
                    comp_s << std::fixed << std::setprecision(4) << comp_sparsities[comp];
                    rv.log(cat("  Comp ", comp,
                            " | sp=", comp_s.str(),
                            " | delta_A=", delta_A,
                            " | delta_K=", delta_K,
                            " | scale_A=", wAPLKC_scales[comp],
                            " | scale_K=", wKCAPL_scales[comp]));
                }

                // TODO delete
                // for debugging + trying to support scaling of arbitrary positive
                // vector wAPLKC/wKCAPL inputs
                if (p.kc.preset_wAPLKC) {
                    // collect unique APL→KC scales
                    std::set<double> uniqA;
                    for (int i = 0; i < rv.kc.wAPLKC.rows(); ++i)
                        uniqA.insert(rv.kc.wAPLKC(i, 0));

                    // log only the count of unique scales
                    std::ostringstream ossA;
                    ossA << "number of unique wAPLKC scales: " << uniqA.size();
                    rv.log(ossA.str());
                }

                if (p.kc.preset_wKCAPL) {
                    // collect unique KC→APL scales
                    std::set<double> uniqK;
                    for (int i = 0; i < rv.kc.wKCAPL.cols(); ++i)
                        uniqK.insert(rv.kc.wKCAPL(0, i));

                    // log only the count of unique scales
                    std::ostringstream ossK;
                    ossK << "number of unique wKCAPL scales: " << uniqK.size();
                    rv.log(ossK.str());
                }
                

                rv.kc.tuning_iters++;
            }

            //rv.log(cat("** t", omp_get_thread_num(), " @ before testing"));
            /* Run through a bunch of odors to test sparsity. */


           

            //rv.log(cat("** t", omp_get_thread_num(), " @ after testing"));

#pragma omp single
            {

                // KCmean_st = (KCmean_st.array() > 0.0).select(1.0, KCmean_st);
                // sp = KCmean_st.mean();

                // after building resp (KC x nCols) as 0/1:
                double active_claw_pairs = 0.0;
                for (unsigned claw = 0; claw < num_claws; ++claw) {
                    unsigned kc = rv.kc.claw_to_kc[claw];
                    active_claw_pairs += KCmean_st.row(kc).sum();
                }
                double global_claw_sparsity = active_claw_pairs / (double(num_claws) * spikes.cols());
                rv.log(cat("Overall claw-defined sparsity after tuning: ", global_claw_sparsity));
                sp = global_claw_sparsity; 


                double active_kcs = KCmean_st.sum();
                rv.log(cat("Iteration ", rv.kc.tuning_iters, " | Total active KCs: ", active_kcs));

                 // Binarize responses
                    
            
                // Reset per-compartment sparsity accumulators
                std::fill(comp_sparsities.begin(), comp_sparsities.end(), 0.0);  // FOR SPARSITY CHECK
            
                // Compute new sparsities
                std::vector<double> claw_active_counts(n_compartments, 0.0);
                const unsigned nCols = KCmean_st.cols();

                for (int comp = 0; comp < n_compartments; ++comp) {
                    double sum_active = 0.0;

                    // iterate claws that belong to this compartment
                    for (int claw : compartment_claws[comp]) {
                        unsigned kc = rv.kc.claw_to_kc[claw];  // parent KC
                        // row(kc).sum() counts how many odors this KC fired for (because KCmean_st is 0/1)
                        sum_active += KCmean_st.row(kc).sum();
                    }

                    // normalize by number of claws and #odors considered
                    const double denom = std::max<size_t>(1, compartment_claws[comp].size()) * double(nCols);
                    claw_active_counts[comp] = sum_active;
                    comp_sparsities[comp]    = sum_active / denom;  // <-- claw-defined sparsity
                }
                
            }
            
            // format global sparsity to 4 decimal places
            std::ostringstream sp_ss;
            sp_ss << std::fixed << std::setprecision(4) << sp;

            rv.log(cat("** t", omp_get_thread_num(),
                    " @ before bottom cond [",
                    "sp=", sp_ss.str(),
                    ", i=", rv.kc.tuning_iters,
                    ", tgt=", p.kc.sp_target,
                    ", acc=", p.kc.sp_acc,
                    ", I=", p.kc.max_iters,
                    "]"));

        // logic if calculating per compartmental deltas
        // int n_converged = 0;
        // static std::vector<int> consec_within(n_compartments, 0);
        // const int K = 2;  // require 2 consecutive iterations within tolerance
        // for (int comp = 0; comp < n_compartments; ++comp) {
        //     double rel_diff = std::abs(comp_sparsities[comp] - p.kc.sp_target) / p.kc.sp_target;
        //     if (rel_diff <= p.kc.sp_acc) consec_within[comp]++; else consec_within[comp] = 0;
        //     converged[comp] = (consec_within[comp] >= K);
        //     if (converged[comp]) n_converged++;
        // }
        int n_converged = 0;
        for (int comp = 0; comp < n_compartments; ++comp) {
            double rel_diff = std::abs(comp_sparsities[comp] - p.kc.sp_target) / p.kc.sp_target;
            bool within = (rel_diff <= p.kc.sp_acc);
            converged[comp] = within;   // <-- overwrite every iteration
            if (within) n_converged++;
        }
        if (n_converged == n_compartments) {
            rv.log("All compartments converged!");
            break;
        }
        if (rv.kc.tuning_iters > p.kc.max_iters) {
            rv.log("WARNING: Max iterations reached. Some compartments may not have converged.");
            break;
        }
        // two deltas method
        } 
        
        // original single delta method
        // while ((abs(sp - p.kc.sp_target) > (p.kc.sp_acc * p.kc.sp_target))
        //         && (rv.kc.tuning_iters <= p.kc.max_iters)); 
        //rv.log(cat("** t", omp_get_thread_num(), " @ exit"));
#pragma omp barrier
#pragma omp single
        {
            rv.kc.tuning_iters--;
        }
    }}

    // Declare exactly the same temporaries used inside the tuner:
    Matrix Vm_end(p.kc.N,    p.time.steps_all());
    Matrix spikes_end(p.kc.N, p.time.steps_all());
    Matrix nves_end(p.kc.N,   p.time.steps_all());
    Matrix inh_end(n_compartments, p.time.steps_all()), Is_end(n_compartments, p.time.steps_all());

    // Build a response matrix exactly as in the tuning loop: one column per subsampled odor
    unsigned nCols = 1 + ((tlist.size() - 1) / p.kc.apltune_subsample);
    Matrix resp(p.kc.N, nCols);

    for (unsigned i = 0; i < tlist.size(); i += p.kc.apltune_subsample) {
        // run a KC sim exactly as you do above
        sim_KC_layer(p, rv,
            rv.pn.sims[tlist[i]],
            rv.ffapl.vm_sims[tlist[i]],
            Vm_end, spikes_end, nves_end, inh_end, Is_end);

            // sum across time, then binarize  
        resp.col(i / p.kc.apltune_subsample) =
            (spikes_end.rowwise().sum().array() > 0.0).cast<double>();
    }
    
    // after building resp (KC x nCols) as 0/1:
    double active_claw_pairs = 0.0;
    for (unsigned claw = 0; claw < num_claws; ++claw) {
        unsigned kc = rv.kc.claw_to_kc[claw];
        active_claw_pairs += resp.row(kc).sum();
    }
    double global_claw_sparsity = active_claw_pairs / (double(num_claws) * nCols);
    rv.log(cat("Overall claw-defined sparsity after tuning: ", global_claw_sparsity));
    // double overallS = resp.mean();
    // rv.log(cat("Overall sparsity after tuning: ", overallS));

    // TODO delete?
    // rv.log(cat("FINAL rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));
    // rv.log(cat("FINAL rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

    // TODO always log tuned parameters at end (fixed_thr, wAPLKC/wKCAPL when not
    // preset, or wAPLKC_scale/wKCAPL_scale when preset)
    rv.log("done fitting sparseness");
}




void sim_ORN_layer(
        ModelParams const& p, RunVars const& rv,
        int odorid,
        Matrix& orn_t) {
    /* Initialize with spontaneous activity. */
    orn_t = p.orn.data.spont*p.time.row_all();

    // TODO TODO can orn_t go negative? i think i'm seeing that in some outputs???
    // is that reasonable?
    // TODO inspect some timecourses where it goes negative?
    // TODO TODO see >=0 constraining line in sim_PN_layer (?)

    /* "Odor input to ORNs" (Kennedy comment)
     * Smoothed timeseries of spont...odor rate...spont */
    Matrix   odor = orn_t + p.orn.data.delta.col(odorid)*p.time.stim.row_all();
    smoothts_exp(odor, 0.02/p.time.dt); // where does 0.02 come from!?

    double mul = p.time.dt/p.orn.taum;
    for (unsigned t = 1; t < p.time.steps_all(); t++) {
        orn_t.col(t) = orn_t.col(t-1)*(1.0-mul) + odor.col(t)*mul;
    }
}
void sim_LN_layer(
        ModelParams const& p,
        Matrix const& orn_t,
        Row& inhA, Row& inhB) {
    Row potential(1, p.time.steps_all()); potential.setConstant(300.0);
    Row response(1, p.time.steps_all());  response.setOnes();
    inhA.setConstant(50.0);
    inhB.setConstant(50.0);
    double inh_LN = 0.0;

    double dinhAdt, dinhBdt, dLNdt;
    double scaling = double(get_ngloms(p))/double(p.orn.n_physical_gloms);
    for (unsigned t = 1; t < p.time.steps_all(); t++) {
        dinhAdt = -inhA(t-1) + response(t-1);
        dinhBdt = -inhB(t-1) + response(t-1);
        dLNdt =
            -potential(t-1)
            +pow(orn_t.col(t-1).mean()*scaling, 3.0)/scaling/2.0*inh_LN;
        inhA(t) = inhA(t-1) + dinhAdt*p.time.dt/p.ln.tauGA;
        inhB(t) = inhB(t-1) + dinhBdt*p.time.dt/p.ln.tauGB;
        inh_LN = p.ln.inhsc/(p.ln.inhadd+inhA(t));
        potential(t) = potential(t-1) + dLNdt*p.time.dt/p.ln.taum;
        //response(t) = potential(t) > lnp.thr ? potential(t)-lnp.thr : 0.0;
        response(t) = (potential(t)-p.ln.thr)*double(potential(t)>p.ln.thr);
    }
}
void sim_PN_layer(
        ModelParams const& p, RunVars const& rv,
        Matrix const& orn_t, Row const& inhA, Row const& inhB,
        Matrix& pn_t) {
    // TODO verify this isn't actually making noise (both params 0? or sd at least?)?
    // it should be seed-able if it is
    std::normal_distribution<double> noise(p.pn.noise.mean, p.pn.noise.sd);

    Column spont  = p.orn.data.spont*p.pn.inhsc/(p.orn.data.spont.sum()+p.pn.inhadd);
    pn_t          = p.orn.data.spont*p.time.row_all();
    double inh_PN = 0.0;

    Column orn_delta;
    Column dPNdt;
    for (unsigned t = 1; t < p.time.steps_all(); t++) {
        orn_delta = orn_t.col(t-1)-p.orn.data.spont;
        dPNdt = -pn_t.col(t-1) + spont;
        dPNdt +=
            200.0*((orn_delta.array()+p.pn.offset)*p.pn.tanhsc/200.0*inh_PN).matrix().unaryExpr<double(*)(double)>(&tanh);
        add_randomly([&noise](){return noise(g_randgen);}, dPNdt);

        inh_PN = p.pn.inhsc/(p.pn.inhadd+0.25*inhA(t)+0.75*inhB(t));
        pn_t.col(t) = pn_t.col(t-1) + dPNdt*p.time.dt/p.pn.taum;

        // TODO TODO why not do something like this in sim_ORN_layer case too?
        // ann also handle the 2 cases the same way?
        pn_t.col(t) = (0.0 < pn_t.col(t).array()).select(pn_t.col(t), 0.0);
    }
}
void sim_FFAPL_layer(
        ModelParams const& p, RunVars const& rv,
        Matrix const& pn_t,
        Vector& ffapl_t, Vector& coef_t) {
    ffapl_t.setZero();
    coef_t.setZero();

    //Column pn_spont = p.orn.data.spont*p.pn.inhsc/(p.orn.data.spont.sum()+p.pn.inhadd);
    Column pn_spont = sample_PN_spont(p, rv);

    double (*coef_calc)(ModelParams const&, Column const&, Column const&);
    coef_calc =
        p.ffapl.coef == "gini" ? ffapl_coef_gini :
        p.ffapl.coef == "lts" ? ffapl_coef_lts :
        (abort(), nullptr);

    double dVdt;
    for (unsigned t = 1; t < p.time.steps_all(); t++) {
        coef_t(t) = coef_calc(p, pn_t.col(t-1), pn_spont);
        dVdt = -ffapl_t(t-1) + p.ffapl.w*coef_t(t)*pn_t.col(t-1).sum();
        ffapl_t(t) = ffapl_t(t-1) + dVdt*p.time.dt/p.ffapl.taum;
    }

    double spont = ffapl_t(p.time.stim.start_step()-1);
    if (p.ffapl.nneg) {
        ffapl_t = (spont < ffapl_t.array()).select(ffapl_t, spont);
    }
    if (p.ffapl.zero) {
        ffapl_t = ffapl_t.array() - spont;
    }
}
void sim_KC_layer(
    ModelParams const& p, RunVars const& rv,
    Matrix const& pn_t, Vector const& ffapl_t,
    Matrix& Vm, Matrix& spikes, Matrix& nves, Matrix& inh, Matrix& Is)
{
    // Determine number of compartments
    // int n_compartments = rv.kc.claw_compartments.maxCoeff() + 1;

    Vm.setZero();
    spikes.setZero();
    nves.setOnes();
    inh.setZero();
    Is.setZero();

    float use_ffapl = float(!p.kc.ignore_ffapl);
    if(p.kc.wPNKC_one_row_per_claw){
        if (p.kc.claw_sp){
            rv.log("enterd claw_sp = True branch of sim_KC_layer");
            unsigned num_claws = rv.kc.claw_to_kc.size();
           
            assert(rv.kc.wKCAPL.rows()==1 && rv.kc.wKCAPL.cols()==num_claws);
            assert(rv.kc.wAPLKC.rows()==num_claws && rv.kc.wAPLKC.cols()==1);
            // build a KC→list<claws> map once (you can cache this outside the loop):

            // // Sanity on mapping range
            // int max_kc = rv.kc.claw_to_kc.maxCoeff();
            // int min_kc = rv.kc.claw_to_kc.minCoeff();

            // // Strong invariants
            // assert(min_kc >= 0 && "claw_to_kc contains negative KC index");
            // assert(max_kc < int(p.kc.N) && "claw_to_kc index >= N");

            // something failed here!~!!!!!!!!    
            // std::vector<std::vector<unsigned>> kc_to_claws(p.kc.N);
            // for (unsigned claw = 0; claw < num_claws; ++claw) {
            //     unsigned kc = rv.kc.claw_to_kc[claw];
            //     kc_to_claws[kc].push_back(claw);
            // }
            // rv.log("kc_to_claw construction passed");
            // what if a KC has more than one claws: 
            for (unsigned t = p.time.start_step() + 1; t < p.time.steps_all(); ++t) {
                // --- KC→APL drive per compartment ---
                Eigen::VectorXd dIsdt = -Is.col(t - 1);
                for (unsigned claw = 0; claw < num_claws; ++claw) {
                    int comp = rv.kc.claw_compartments(claw);
                    unsigned kc = rv.kc.claw_to_kc[claw];
                    double ves_spk = nves(kc, t - 1) * spikes(kc, t - 1); // should this be in KC? 
                    dIsdt(comp) += rv.kc.wKCAPL(0, claw) * ves_spk * 1e4; // wait what are the dimensions of declared dIsdt? 
                }
                // --- APL→KC inhibition derivative per compartment ---
                Eigen::VectorXd dinhdt = -inh.col(t - 1) + Is.col(t - 1);

                // Integrate compartment signals
                Is.col(t)  = Is.col(t - 1)
                            + dIsdt * p.time.dt / p.kc.tau_apl2kc;
                inh.col(t) = inh.col(t - 1)
                            + dinhdt * p.time.dt / p.kc.apl_taum;

                // --- PN→KC feedforward drive (per claw) ---
                Eigen::VectorXd claw_drive = rv.kc.wPNKC * pn_t.col(t); // PNKC should already be in the dimension of claws? given that one_claw_per_row
                Eigen::VectorXd pn_drive(p.kc.N);
                pn_drive.setZero(); // ? are you sure what is this entire thing doing here? 
                for (unsigned claw = 0; claw < num_claws; ++claw) {
                    unsigned kc = rv.kc.claw_to_kc[claw];
                    pn_drive[kc] += claw_drive[claw];   
                }

                // --- Collapse compartmental inhibition back onto each KC ---
                Eigen::VectorXd kc_inh(p.kc.N);
                kc_inh.setZero(); 
                for (unsigned claw = 0; claw < num_claws; ++claw) {
                    unsigned kc   = rv.kc.claw_to_kc[claw];
                    int      comp = rv.kc.claw_compartments(claw);
                    // sum each claw’s compartmental inh, then scale by that claw’s APL→KC weight
                    kc_inh[kc] += inh(comp, t - 1) * rv.kc.wAPLKC(claw, 0);
                }
                // --- KC membrane potential ODE + FFAPL ---
                Eigen::VectorXd dKCdt =
                    (-Vm.col(t - 1) + pn_drive - kc_inh).array()
                    - use_ffapl * ffapl_t(t - 1);

                Vm.col(t) = Vm.col(t - 1)
                        + dKCdt * p.time.dt / p.kc.taum;

                // --- Synaptic‐vesicle dynamics ---
                nves.col(t) = nves.col(t - 1)
                    + p.time.dt
                    * ((1.0 - nves.col(t - 1).array()) / p.kc.tau_r).matrix()
                    - (p.kc.ves_p
                    * spikes.col(t - 1).array()
                    * nves.col(t - 1).array()).matrix();

                // --- Spike generation & reset ---
                auto const thr_comp = Vm.col(t).array() > rv.kc.thr.array();
                spikes.col(t) = thr_comp.select(1.0, spikes.col(t));  
                Vm.col(t)     = thr_comp.select(0.0, Vm.col(t));
            }
        } else {
            // Column dKCdt;
            // for (unsigned t = p.time.start_step()+1; t < p.time.steps_all(); t++) {
            //     double dIsdt = -Is(t-1) + (
            //             rv.kc.wKCAPL*(nves.col(t-1).array()*spikes.col(t-1).array()).matrix())(0,0)*1e4;
            //     double dinhdt = -inh(t-1) + Is(t-1);
                    
            //         // claw-level drive: one entrty per claw
            //         //  rv.kc.wPNKC: a matrix of size (nClaws x nGloms)
            //         // pn_t.col(t): a vector of size (nGloms) givine the PN activity at time step t.  
            //         // multiplication: standard matrix-vector, a length-nClaws VectorXd
            //     Eigen::VectorXd claw_drive = rv.kc.wPNKC * pn_t.col(t);                // size = nClaws
            //         // collapse to true KC-level drive
            //         // initialize KC-level accumulator
            //         // pn_drive is a placeholder for the summed drive each KC will recieve 
            //         // p.kc.N is the number of KCs
            //     Eigen::VectorXd pn_drive = Eigen::VectorXd::Zero(p.kc.N);           // size = nKCs
            //     const Eigen::Index n_claws = rv.kc.claw_to_kc.size();
            //     for (Eigen::Index claw = 0; claw < n_claws; ++claw) {
            //         unsigned kc = rv.kc.claw_to_kc[claw];  // already 0..N-1
            //         pn_drive[kc] += claw_drive[claw];
            //     }

            //         // plug collapsed drive into your ODE exactly as before
            //     dKCdt =
            //         (-Vm.col(t-1)
            //         + pn_drive
            //         - rv.kc.wAPLKC * inh(t-1)).array()
            //         - use_ffapl * ffapl_t(t-1);
            //     Vm.col(t) = Vm.col(t-1) + dKCdt*p.time.dt/p.kc.taum;
            //     inh(t)    = inh(t-1)    + dinhdt*p.time.dt/p.kc.apl_taum;
            //     Is(t)     = Is(t-1)     + dIsdt*p.time.dt/p.kc.tau_apl2kc;

            //     nves.col(t) = nves.col(t-1);
            //     nves.col(t) += p.time.dt*((1.0-nves.col(t-1).array()).matrix()/p.kc.tau_r) - (p.kc.ves_p*spikes.col(t-1).array()*nves.col(t-1).array()).matrix();

            //     auto const thr_comp = Vm.col(t).array() > rv.kc.thr.array();
            //     spikes.col(t) = thr_comp.select(1.0, spikes.col(t)); // either go to 1 or _stay_ at 0.
            //     Vm.col(t) = thr_comp.select(0.0, Vm.col(t)); // very abrupt repolarization!
            // }
            Column dKCdt;
            double total_claw_drive = 0.0;
            double total_pn_drive = 0.0;
            double total_kc_apl_inh = 0.0;
            for (unsigned t = p.time.start_step()+1; t < p.time.steps_all(); t++) {
                // Calculate the KC-level activity, a vector of size (p.kc.N, 1)
                Eigen::VectorXd kc_activity = (nves.col(t-1).array() * spikes.col(t-1).array()).matrix();

                // Sum the weighted activity of all KCs to get a single APL input value.
                // This resolves the dimension mismatch.
                double kc_apl_drive = 0.0;
                const Eigen::Index n_claws = rv.kc.claw_to_kc.size();
                for (Eigen::Index claw = 0; claw < n_claws; ++claw) {
                    unsigned kc = rv.kc.claw_to_kc[claw];
                    kc_apl_drive += rv.kc.wKCAPL(claw, 0) * kc_activity[kc];
                }
                
                 double dIsdt = -Is(t-1) + kc_apl_drive * 1e4;

                double dinhdt = -inh(t-1) + Is(t-1);
                // claw-level drive: one entrty per claw
                // rv.kc.wPNKC: a matrix of size (nClaws x nGlos)
                // pn_t.col(t): a vector of size (nGloms) givine the PN activity at time step t. 
                // multiplication: standard matrix-vector, a length-nClaws VectorXd
                Eigen::VectorXd claw_drive = rv.kc.wPNKC * pn_t.col(t);       // size = nClaws
                
                // collapse to true KC-level drive
                // initialize KC-level accumulator
                // pn_drive is a placeholder for the summed drive each KC will recieve 
                // p.kc.N is the number of KCs
                Eigen::VectorXd pn_drive = Eigen::VectorXd::Zero(p.kc.N);      // size = nKCs
                for (Eigen::Index claw = 0; claw < n_claws; ++claw) {
                    unsigned kc = rv.kc.claw_to_kc[claw]; // already 0..N-1
                    pn_drive[kc] += claw_drive[claw];
                }

                // --- FIX: Map the APL inhibition from claw level to KC level ---
                Eigen::VectorXd kc_apl_inh = Eigen::VectorXd::Zero(p.kc.N); // size = nKCs
                for (Eigen::Index claw = 0; claw < n_claws; ++claw) {
                    unsigned kc = rv.kc.claw_to_kc[claw];
                    // The APL inhibition is weighted by the APL->KC weight
                    // and applied to the corresponding KC.
                    kc_apl_inh[kc] += rv.kc.wAPLKC(claw, 0) * inh(t - 1);
                }
                
                total_claw_drive += claw_drive.mean();
                total_pn_drive += pn_drive.mean();
                total_kc_apl_inh += kc_apl_inh.mean();    
                // --- Now use the correctly sized KC-level inhibition ---
                dKCdt =
                    (-Vm.col(t-1)
                    + pn_drive
                    - kc_apl_inh).array() // Now this term has the correct size
                    - use_ffapl * ffapl_t(t-1);
                
                Vm.col(t) = Vm.col(t-1) + dKCdt*p.time.dt/p.kc.taum;
                inh(t)    = inh(t-1)    + dinhdt*p.time.dt/p.kc.apl_taum;
                Is(t)     = Is(t-1)     + dIsdt*p.time.dt/p.kc.tau_apl2kc;

                nves.col(t) = nves.col(t-1);
                nves.col(t) += p.time.dt*((1.0-nves.col(t-1).array()).matrix()/p.kc.tau_r) - (p.kc.ves_p*spikes.col(t-1).array()*nves.col(t-1).array()).matrix();

                auto const thr_comp = Vm.col(t).array() > rv.kc.thr.array();
                spikes.col(t) = thr_comp.select(1.0, spikes.col(t)); // either go to 1 or _stay_ at 0.
                Vm.col(t) = thr_comp.select(0.0, Vm.col(t)); // very abrupt repolarization!
            }
            double num_time_steps = p.time.steps_all() - (p.time.start_step() + 1);

            // Now you can calculate the mean outside the loop and log the values.
            // rv.log(cat("After sim_KC_layer: ", "wAPLKC mean: ", rv.kc.wAPLKC.mean(),
            //     ", claw_drive mean: ", total_claw_drive / num_time_steps,
            //     ", pn_drive mean: ", total_pn_drive / num_time_steps,
            //     ", kc_apl_inh mean: ", total_kc_apl_inh / num_time_steps,
            //     ", Vm mean: ", Vm.mean(),
            //     ", Spikes mean: ", spikes.mean()));
        }
    } else {
        Column dKCdt;
        for (unsigned t = p.time.start_step()+1; t < p.time.steps_all(); t++) {
            double dIsdt = -Is(t-1) + (
                    rv.kc.wKCAPL*(nves.col(t-1).array()*spikes.col(t-1).array()).matrix())(0,0)*1e4;
            double dinhdt = -inh(t-1) + Is(t-1);

            dKCdt =
                (-Vm.col(t-1)
                +rv.kc.wPNKC*pn_t.col(t)
                -rv.kc.wAPLKC*inh(t-1)).array()
                -use_ffapl*ffapl_t(t-1);

            Vm.col(t) = Vm.col(t-1) + dKCdt*p.time.dt/p.kc.taum;
            inh(t)    = inh(t-1)    + dinhdt*p.time.dt/p.kc.apl_taum;
            Is(t)     = Is(t-1)     + dIsdt*p.time.dt/p.kc.tau_apl2kc;

            nves.col(t) = nves.col(t-1);
            nves.col(t) += p.time.dt*((1.0-nves.col(t-1).array()).matrix()/p.kc.tau_r) - (p.kc.ves_p*spikes.col(t-1).array()*nves.col(t-1).array()).matrix();

            auto const thr_comp = Vm.col(t).array() > rv.kc.thr.array();
            spikes.col(t) = thr_comp.select(1.0, spikes.col(t)); // either go to 1 or _stay_ at 0.
            Vm.col(t) = thr_comp.select(0.0, Vm.col(t)); // very abrupt repolarization!
        }
        // rv.log(cat("After sim_KC_layer: ", "wAPLKC mean: ", rv.kc.wAPLKC.mean(), ", ", "Vm mean: ", Vm.mean(), ", ", "Spikes mean: ", spikes.mean()));
    }
}

/*
void sim_KC_layer(
    ModelParams const& p, RunVars const& rv,
    Matrix const& pn_t, Vector const& ffapl_t,
    Matrix& Vm, Matrix& spikes, Matrix& nves, Matrix& inh, Matrix& Is)
{
    Vm.setZero();
    spikes.setZero();
    nves.setOnes();
    inh.setZero();
    Is.setZero();

    // int n_compartments = rv.kc.claw_compartments.maxCoeff() + 1;
    float use_ffapl = float(!p.kc.ignore_ffapl);

    Column dKCdt;  // alias for Eigen::VectorXd

    for (unsigned t = p.time.start_step()+1; t < p.time.steps_all(); ++t) {

        // KC→APL drive per compartment ---
        Eigen::VectorXd dIsdt = - Is.col(t-1).array();   // start with –Is_prev
        // loop through the claws; check which compartment each claw belongs to (either 0 or 1)
        // find the KC index of that claw; 
        for (Eigen::Index claw = 0; claw < rv.kc.claw_to_kc.size(); ++claw) {
            int comp = rv.kc.claw_compartments[claw];  // which compartment
            unsigned kc = rv.kc.claw_to_kc[claw];         // which KC
            // how many vesicles that KC used when it spiked last tick:
            double ves_spk = nves(kc, t-1) * spikes(kc, t-1);
            // accumulate weighted KC→APL drive into compartment “comp”
            dIsdt(comp) += rv.kc.wKCAPL(0, kc) * ves_spk * 1e4;
        }

        // APL→KC inhibition derivative (per compartment) 
        Eigen::VectorXd dinhdt =
            - inh.col(t-1).array()
            + Is.col(t-1).array();

        // Integrate each compartment forward 
        Is.col(t) = Is.col(t-1) + dIsdt  * p.time.dt / p.kc.tau_apl2kc;
        inh.col(t) = inh.col(t-1) + dinhdt * p.time.dt / p.kc.apl_taum;

        // PN→KC 
        Eigen::VectorXd claw_drive = rv.kc.wPNKC * pn_t.col(t);  // nClaws

        // collapse claws into KC input
        // add up all the claw drive for that specific KC
        Eigen::VectorXd pn_drive = Eigen::VectorXd::Zero(p.kc.N);
        for (Eigen::Index claw = 0; claw < rv.kc.claw_to_kc.size(); ++claw) {
            unsigned kc = rv.kc.claw_to_kc[claw];
            pn_drive[kc] += claw_drive[claw];
        }

        // Collapse compartmental inh back onto each KC 
        Eigen::VectorXd kc_inh = Eigen::VectorXd::Zero(p.kc.N);
        for (Eigen::Index claw = 0; claw < rv.kc.claw_to_kc.size(); ++claw)  {
            unsigned kc = rv.kc.claw_to_kc[claw]; // locate the KC
            int comp = rv.kc.claw_compartments[claw]; // locate the compartment
            kc_inh[kc] += inh(comp, t-1); // add the previous inh of that compartment to the KC; 
        }
        // KC scaling, do it here:
        kc_inh.array() *= rv.kc.wAPLKC.array();

        // KC voltage ODE and integration ---
        dKCdt =
            (- Vm.col(t-1)
             + pn_drive
             - kc_inh
            ).array()
            - use_ffapl * ffapl_t(t-1);

        Vm.col(t) = Vm.col(t-1)
                   + dKCdt * p.time.dt / p.kc.taum;

        // Synaptic‐vesicle dynamics ---
        nves.col(t) = nves.col(t-1)
            + p.time.dt * ((1.0 - nves.col(t-1).array()) / p.kc.tau_r).matrix()
            - (p.kc.ves_p * spikes.col(t-1).array()
               * nves.col(t-1).array()).matrix();

        // Spike generation & reset ---
        auto const thr_comp = Vm.col(t).array() > rv.kc.thr.array();
        spikes.col(t) = thr_comp.select(1.0, spikes.col(t));  // latch‐on
        Vm.col(t) = thr_comp.select(0.0, Vm.col(t));      // abrupt repolarization
        

        // test claw_to_KC.size()* 
        // rv.log(cat("DEBUG: claw_to_KC.size() = ", rv.kc.claw_to_kc.size()));
        // std::cout << "DEBUG: claw_to_KC.size() = " << rv.kc.claw_to_kc.size() << std::endl;

    }
}
*/

void run_ORN_LN_sims(ModelParams const& p, RunVars& rv) {
    rv.log("running ORN and LN sims");
    std::vector<unsigned> simlist = get_simlist(p);
#pragma omp parallel
    {
        Matrix orn_t(get_ngloms(p), p.time.steps_all());
        Row inhA(1, p.time.steps_all());
        Row inhB(1, p.time.steps_all());
#pragma omp for
        for (unsigned j = 0; j < simlist.size(); j++) {
            unsigned i = simlist[j];
            sim_ORN_layer(p, rv, i, orn_t);
            sim_LN_layer(p, orn_t, inhA, inhB);
#pragma omp critical
            {   
                rv.log(cat(orn_t.rows()));
                rv.log(cat(orn_t.cols()));
                rv.orn.sims[i] = orn_t;
                rv.ln.inhA.sims[i] = inhA;
                rv.ln.inhB.sims[i] = inhB;
            }

            /*
            sim_ORN_layer(p, rv, i, rv.orn.sims[i]);
            sim_LN_layer(
                    p, rv.orn.sims[i],
                    rv.ln.inhA.sims[i], rv.ln.inhB.sims[i]);
                    */
        }
    }
}
void run_PN_sims(ModelParams const& p, RunVars& rv) {
    rv.log("running PN sims");
    std::vector<unsigned> simlist = get_simlist(p);
#pragma omp parallel for
    for (unsigned j = 0; j < simlist.size(); j++) {
        unsigned i = simlist[j];
        sim_PN_layer(
                p, rv,
                rv.orn.sims[i], rv.ln.inhA.sims[i], rv.ln.inhB.sims[i],
                rv.pn.sims[i]);
    }
}
void run_FFAPL_sims(ModelParams const& p, RunVars& rv) {
    std::vector simlist = get_simlist(p);
#pragma omp parallel for
    for (unsigned j = 0; j < simlist.size(); j++) {
        unsigned i = simlist[j];
        sim_FFAPL_layer(
                p, rv,
                rv.pn.sims[i],
                rv.ffapl.vm_sims[i], rv.ffapl.coef_sims[i]);
    }
}
void run_KC_sims(ModelParams const& p, RunVars& rv, bool regen) {
    if (regen) {
        rv.log("generating new KC replicate");
        // TODO want to add optional flag to allow fit_sparseness to run w/o re-gening
        // wPNKC? likely not relevant if i only need multiple run_KC_sims calls for
        // deterministic wPNKC (e.g. from hemibrain)? would just want to be able to get
        // rv.kc.pks and then pick thresholds based on that in python, with another
        // run_KC_sims call after
        build_wPNKC(p, rv);
        
        // If KC_row = True, wAPLKC and wKCAPL will have length of number of KCs, otherwise they will have the length of number of claws 
        // Number of unique weights = number of compartments 
        rv.log(cat("one_row_per_claw true or not: ", p.kc.wPNKC_one_row_per_claw));
        rv.log(cat("kc_ids size: ", p.kc.kc_ids.size()));
        const size_t n = std::min<size_t>(10, p.kc.kc_ids.size());
        std::ostringstream oss;
        oss << "kc_ids first " << n << ": ";
        for (size_t i = 0; i < n; ++i) {
            if (i) oss << ", ";
            oss << p.kc.kc_ids[i];   // indices 0..n-1
        }
        rv.log(oss.str());
        rv.log(cat("claw_to_kc size: ", rv.kc.claw_to_kc.size()));
        if (p.kc.claw_sp) {
            // wAPLKC should be one‐per‐KC
            fit_sparseness_claw(p, rv);
            assert(rv.kc.wAPLKC.rows() == int(rv.kc.claw_compartments.size()));
        } else {
            // wAPLKC should be one‐per‐claw
            fit_sparseness(p, rv);
            if (p.kc.wPNKC_one_row_per_claw){
                assert(rv.kc.wAPLKC.rows() == int(rv.kc.claw_compartments.size()));
            } else {
                assert(rv.kc.wAPLKC.rows() == int(p.kc.N));
            }
            // assert(rv.kc.wAPLKC.rows() == int(num_claws));
        }
        // // For Debugging Purpose 
        // // Test: whether the index of wAPLKC and wKCAPL matches 
        // Eigen::VectorXd waplkc = rv.kc.wAPLKC;
        // Eigen::RowVectorXd wkcapl = rv.kc.wKCAPL;
        // // convert to vectors
        // std::vector<double> v_waplkc(waplkc.data(), waplkc.data() + waplkc.size());
        // std::vector<double> v_wkcapl(wkcapl.data(), wkcapl.data() + wkcapl.size());

        // // 3) build kc → set<compartment>
        // std::vector<std::unordered_set<int>> kc_to_comps(p.kc.N);
        // for (Eigen::Index claw = 0; claw < rv.kc.claw_to_kc.size(); ++claw) {
        //     unsigned kc   = rv.kc.claw_to_kc[claw];
        //     int      comp = rv.kc.claw_compartments[claw];
        //     kc_to_comps[kc].insert(comp);
        // }

        // // 4) collapse to single comp per KC (assume non‐empty)
        // std::vector<int> kc_comp(p.kc.N);
        // for (unsigned kc = 0; kc < p.kc.N; ++kc) {
        //     if (kc_to_comps[kc].empty()) {
        //         throw std::runtime_error(
        //             "KC " + std::to_string(kc) + " has no compartment!"
        //         );
        //     }
        //     kc_comp[kc] = *kc_to_comps[kc].begin();
        // }

        // // 5) extract representative weight per compartment
        // constexpr double tol = 1e-9;
        // std::map<int,double> rep_wapl, rep_wkpl;

          

        // // 6a) Count frequency of each weight in wAPLKC
        // std::map<double,int> freq_wapl;
        // for (double w : v_waplkc) {
        //     freq_wapl[w]++;
        // }
        // rv.log("wAPLKC weight frequencies:");
        // for (auto const& [w,count] : freq_wapl) {
        //     rv.log("  weight " + std::to_string(w)
        //         + " appears " + std::to_string(count) + " times");
        // }

        // // 6b) Count how many elements fall into each compartment
        // std::map<int,int> freq_comp;
        // if (KC_row) {
        //     // v_waplkc is per-KC
        //     for (int comp : kc_comp) {
        //         freq_comp[comp]++;
        //     }
        // } else {
        //     // v_waplkc is per-claw
        //     for (size_t i = 0; i < v_waplkc.size(); ++i) {
        //         int comp = rv.kc.claw_compartments[i];
        //         freq_comp[comp]++;
        //     }
        // }
        // rv.log("Compartment membership counts:");
        // for (auto const& [comp,count] : freq_comp) {
        //     rv.log("  compartment " + std::to_string(comp)
        //         + " has " + std::to_string(count) + " elements");
        // }

        // // how many to print
        // size_t n_print = std::min<size_t>(20,
        //     KC_row
        //     ? kc_comp.size()
        //     : rv.kc.claw_compartments.size()
        // );

        // // 1) print first n_print compartments (KC_row? kc_comp : claw_compartments)
        // rv.log("First " + std::to_string(n_print) + 
        //     (KC_row ? " kc_comp values:" : " claw_compartment values:"));
        // for (size_t i = 0; i < n_print; ++i) {
        //     int comp = KC_row
        //             ? kc_comp[i]
        //             : rv.kc.claw_compartments[i];
        //     rv.log("  [" + std::to_string(i) + "] comp=" +
        //         std::to_string(comp));
        // }

        // // 2) print first n_print wAPLKC
        // rv.log("First " + std::to_string(n_print) + " wAPLKC values:");
        // for (size_t i = 0; i < std::min(n_print, v_waplkc.size()); ++i) {
        //     rv.log("  [" + std::to_string(i) + "] " +
        //         std::to_string(v_waplkc[i]));
        // }

        // // 3) print first n_print wKCAPL
        // rv.log("First " + std::to_string(n_print) + " wKCAPL values:");
        // for (size_t i = 0; i < std::min(n_print, v_wkcapl.size()); ++i) {
        //     rv.log("  [" + std::to_string(i) + "] " +
        //         std::to_string(v_wkcapl[i]));
        // }
        
    }

   

    rv.log("running KC sims");
    std::vector<unsigned> simlist = get_simlist(p);
    if(p.kc.claw_sp){   
        rv.log("got num compartments");
    }

#pragma omp parallel 
{
    Matrix Vm_here;
    if (!p.kc.save_vm_sims) {
        Vm_here = Matrix(p.kc.N, p.time.steps_all());
    } 

    Matrix spikes_here;
    if (!p.kc.save_spike_recordings) {
        spikes_here = Matrix(p.kc.N, p.time.steps_all());
    }

    Matrix nves_here;
    if (!p.kc.save_nves_sims) {
        nves_here = Matrix(p.kc.N, p.time.steps_all());
    }

    Matrix inh_here;
    Matrix Is_here;
    if(p.kc.claw_sp){
        int n_compartments = rv.kc.claw_compartments.maxCoeff() + 1;
        if (!p.kc.save_inh_sims) {
            inh_here = Matrix(n_compartments, p.time.steps_all());
        }

        if (!p.kc.save_Is_sims) {
            Is_here = Matrix(n_compartments, p.time.steps_all());
        }
    } else {
        if (!p.kc.save_inh_sims) {
            inh_here = Matrix(1, p.time.steps_all());
        }

        if (!p.kc.save_Is_sims) {
            Is_here = Matrix(1, p.time.steps_all());
        }
    }
    rv.log("first round of initialization of matrices passed");

    rv.kc.responses.resize(p.kc.N, get_nodors(p));
    rv.kc.spike_counts.resize(p.kc.N, get_nodors(p));
    std::stringstream ss;
    ss << "get_nodors(p): " << get_nodors(p);
    rv.log(ss.str());    // Matrix Vm(p.kc.N, p.time.steps_all()); 
    // Matrix spikes(p.kc.N, p.time.steps_all());
    Matrix respcol;
    Matrix respcol_bin; 
#pragma omp for
    for (unsigned j = 0; j < simlist.size(); j++) {
        unsigned i = simlist[j];
        Matrix& Vm_link = p.kc.save_vm_sims
            ? rv.kc.vm_sims.at(i)
            : Vm_here; 
        Matrix& spikes_link = p.kc.save_spike_recordings
            ? rv.kc.spike_recordings.at(i)
            : spikes_here;
        Matrix& nves_link = p.kc.save_nves_sims
            ? rv.kc.nves_sims.at(i)
            : nves_here;
        Matrix& inh_link = p.kc.save_inh_sims
            ? rv.kc.inh_sims.at(i)
            : inh_here;
        // TODO TODO where does this one get saved to?
        Matrix& Is_link = p.kc.save_Is_sims
            ? rv.kc.Is_sims.at(i)
            : Is_here;
        rv.log("after constructing all the matrices");
        sim_KC_layer(
            p, rv,
            rv.pn.sims[i], rv.ffapl.vm_sims[i],
            Vm_link, spikes_link, nves_link, inh_link, Is_link);
        respcol = spikes_link.rowwise().sum();
        respcol_bin = (respcol.array() > 0.0).select(1.0, respcol);
        rv.log(cat("Stored respcol_bin for odor ", i, " has a mean of ", respcol_bin.mean()));

#pragma omp critical
        rv.kc.responses.col(i) = respcol_bin;
        rv.log(cat("rv.kc.responses.col(i).mean(): ", rv.kc.responses.col(i).mean()));
        rv.kc.spike_counts.col(i) = respcol;
    } 
} // The parallel region ends here.

// **ALL of the following code has been moved here, outside the parallel region,
// to ensure it runs only after all threads have completed.**

if (p.kc.claw_sp){
    std::vector<unsigned> tlist = p.kc.tune_from;
    if (tlist.empty()) {
        for (unsigned i = 0; i < get_nodors(p); ++i) tlist.push_back(i);
    }

    const unsigned nCols = 1 + ((tlist.size() - 1) / p.kc.apltune_subsample);
    Matrix resp(p.kc.N, nCols);

    // Each column is the KC 0/1 response for a subsampled odor.
    {
        unsigned col = 0;
        for (unsigned k = 0; k < tlist.size(); k += p.kc.apltune_subsample) {
            const unsigned odor = tlist[k];
            // rv.kc.responses is already binarized per odor (KC x odor)
            resp.col(col++) = rv.kc.responses.col(odor);
        }
    }

    // --- Claw-defined sparsity: count (claw, odor) pairs that are active ---
    // If a KC is active for an odor, all claws belonging to that KC are considered active for that odor.
    const unsigned num_claws = static_cast<unsigned>(rv.kc.claw_to_kc.size());

    double active_claw_pairs = 0.0;
    for (unsigned claw = 0; claw < num_claws; ++claw) {
        unsigned kc = rv.kc.claw_to_kc[claw];
        active_claw_pairs += resp.row(kc).sum();  // sum across odors for that KC
    }
    const double global_claw_sparsity =
        active_claw_pairs / (static_cast<double>(num_claws) * static_cast<double>(nCols));
    rv.log(cat("Overall claw-defined sparsity after tuning: ", global_claw_sparsity));

    double final_sp = rv.kc.responses.mean();  
    // double final_sc = rv.kc.spike_counts.mean();
    rv.log(cat("Post-sim global sparsity (C++): ", final_sp));
} else {
    double final_sp = rv.kc.responses.mean();
    if (rv.kc.responses.hasNaN()) {
        rv.log("Warning: The rv.kc.responses matrix contains NaN values.");

        // You can also iterate and print them for more detailed debugging
        for (int r = 0; r < rv.kc.responses.rows(); ++r) {
            for (int c = 0; c < rv.kc.responses.cols(); ++c) {
                if (std::isnan(rv.kc.responses(r, c))) {
                    rv.log(cat("NaN found at row ", r, ", column ", c));
                }
            }
        }
    }
    rv.log(cat("Post-sim global sparsity (C++): ", final_sp));
}
}


void remove_before(unsigned step, Matrix& timecourse) {
    Matrix intermediate = timecourse.block(
            0,                 step,
            timecourse.rows(), timecourse.cols()-step);
    timecourse = intermediate;
}
void remove_all_pretime(ModelParams const& p, RunVars& r) {
    auto cut = [&p](Matrix& m) {
        remove_before(p.time.start_step(), m);
    };
#pragma omp parallel
    {
        // ORN
#pragma omp for
        for (unsigned i = 0; i < r.orn.sims.size(); i++) {
            cut(r.orn.sims[i]);
        }
        // LN
#pragma omp for
        for (unsigned i = 0; i < r.ln.inhA.sims.size(); i++) {
            cut(r.ln.inhA.sims[i]);
        }
#pragma omp for
        for (unsigned i = 0; i < r.ln.inhB.sims.size(); i++) {
            cut(r.ln.inhB.sims[i]);
        }
        // PN
#pragma omp for
        for (unsigned i = 0; i < r.pn.sims.size(); i++) {
            cut(r.pn.sims[i]);
        }
    }
}

std::vector<unsigned> get_simlist(ModelParams const& p) {
    if (p.sim_only.empty()) {
        std::vector<unsigned> ret(get_nodors(p));
        std::iota(std::begin(ret), std::end(ret), 0);
        return ret;
    }
    return p.sim_only;
}


// This version of fit_sparseness_KC has per-compartmental KC sparsity;
//  where wAPLKC and wKCAPL has the length of num_KC
// Likely garbage code; doesn't work logically as KC cannot be assigned to
// a compartment

// void fit_sparseness_KC(ModelParams const& p, RunVars& rv, bool KC_row) {
//     rv.log("fitting sparseness");

//     std::vector<unsigned> tlist = p.kc.tune_from;
//     if (!tlist.size()) {
//         for (unsigned i = 0; i < get_nodors(p); i++) tlist.push_back(i);
//     }

//     /* Calculate spontaneous input to KCs. */
//     // TODO log stuff about PN spont to figure out if part of that isn't init'd
//     // properly?
//     Column spont_in = rv.kc.wPNKC * sample_PN_spont(p, rv);
//     rv.kc.spont_in = spont_in;

    
//     Column wAPLKC_unscaled(p.kc.N, 1);
//     Row wKCAPL_unscaled(1, p.kc.N);
    

//     if (p.kc.preset_wAPLKC) {
//         // TODO delete
//         rv.log(cat("INITIAL rv.kc.wAPLKC.mean(): ", rv.kc.wAPLKC.mean()));

//         // should be a deep copy
//         wAPLKC_unscaled = rv.kc.wAPLKC;

//         // TODO delete
//         rv.log(cat("INITIAL wAPLKC_unscaled.mean(): ", wAPLKC_unscaled.mean()));
//     }
//     if (p.kc.preset_wKCAPL) {
//         // TODO delete
//         rv.log(cat("INITIAL rv.kc.wKCAPL.mean(): ", rv.kc.wKCAPL.mean()));

//         wKCAPL_unscaled = rv.kc.wKCAPL;

//         // TODO delete
//         rv.log(cat("INITIAL wKCAPL_unscaled.mean(): ", wKCAPL_unscaled.mean()));
//     }

//     // TODO do i actually need these vars? don't i still want to assign scaled
//     // wAPLKC/wKCAPL vectors into rv.kc.wAPLKC/wKCAPL at the end
//     /* Should only be used in preset_w[APLKC|KCAPL] = true cases */
    

//     /* Set starting values for the things we'll tune. */
//     // TODO matter? seems to be overwritten below in this case anyway...
//     // (and put inside this conditional to avoid overwriting values set in python, via
//     // pybind11)
//     if (p.kc.tune_apl_weights) {
//         if (!p.kc.preset_wAPLKC) {
//             rv.kc.wAPLKC.setZero();
//         }
//         if (!p.kc.preset_wKCAPL) {
//             rv.kc.wKCAPL.setConstant(1.0/float(p.kc.N));
//         }
//     }
//     // TODO check that, in NOT p.kc.tune_apl_weights case, wAPLKC and wKCAPL are
//     // appropriately initialized? maybe also in preset_wAPLKC/preset_wKCAPL = true
//     // cases above?

//     if (!p.kc.use_vector_thr) {
//         if (!p.kc.use_fixed_thr) {
//             rv.kc.thr.setConstant(1e5); // higher than will ever be reached
//         }
//         else {
//             rv.log(cat("using FIXED threshold: ", p.kc.fixed_thr));
//             // TODO would it ever make sense to have add_fixed_thr_to_spont=False?
//             // when? in any cases i use? doc
//             if (p.kc.add_fixed_thr_to_spont) {
//                 // TODO delete + replace w/ similar commented line below
//                 // (after confirming the 2 things w/ factor 2 cancel out...)
//                 rv.log("adding fixed threshold to 2 * spontaneous PN input to each KC");
//                 //rv.log("adding fixed threshold to spontaneous PN input to each KC");
//                 // TODO TODO what are units of spont_in? doc these as units of fixed_thr
//                 rv.kc.thr = p.kc.fixed_thr + spont_in.array()*2.0;
//             } else {
//                 rv.kc.thr.setConstant(p.kc.fixed_thr);
//             }
//         }
//     } else {
//         rv.log("using prespecified vector KC thresholds");
//         // TODO even want to allow `add_fixed_thr_to_spont = False`? don't think it's
//         // useful now
//         if (p.kc.add_fixed_thr_to_spont) {
//             rv.log("adding threshold to 2 * spontaneous PN input to each KC");

//             // TODO delete
//             // TODO do i need .array() here? also, i assuming changing <x>.array() also
//             // changes values in <x> (assuming it's a Matrix/similar)?
//             rv.log(cat("(before adding spont) rv.kc.thr.mean(): ", rv.kc.thr.mean()));

//             // TODO this line working as intended? (do need LHS .array() to avoid err,
//             // at least w/ RHS as it is here)
//             rv.kc.thr.array() += spont_in.array()*2.0;

//             // TODO delete
//             // TODO do i need .array() here?
//             rv.log(cat("(after adding spont) rv.kc.thr.mean(): ", rv.kc.thr.mean()));
//         }
//     }

//     /* Used for measuring KC voltage; defined here to make it shared across all
//      * threads.*/
//     Matrix KCpks(p.kc.N, tlist.size()); KCpks.setZero();

//     /* Used to store odor response data during APL tuning. */
//     Matrix KCmean_st(p.kc.N, 1+ ((tlist.size() - 1) / p.kc.apltune_subsample));
//     // TODO TODO should this not be computed on first iteration?
//     /* Used to store the current sparsity.
//      * Initially set to the below value because, given default model
//      * parameters, it causes tuning to complete in just one iteration. */
//     double sp = 0.0789;
//     /* Used to count number of times looped; the 'learning rate' is decreased
//      * as 1/sqrt(count) with each iteration. */
//     rv.kc.tuning_iters = 0;

//     int n_compartments = rv.kc.claw_compartments.maxCoeff() + 1;

//     // TO BE REVIEWED
//     // Map each KC to the set of compartments it has claws in
//     std::vector<std::unordered_set<int>> kc_to_compartments(p.kc.N);
//     for (Eigen::Index claw = 0; claw < rv.kc.claw_to_kc.size(); ++claw) {
//         unsigned kc = rv.kc.claw_to_kc[claw];
//         int comp = rv.kc.claw_compartments(claw);
//         kc_to_compartments[kc].insert(comp);
//         // std::cout << "KC" << kc << "is in compartment" << comp << std:: endl;
//     }

//     // Initialize per-compartment APL↔KC weight scalars
//     // std::vector<double> wAPLKC_scales(n_compartments, 2 * ceil(-log(p.kc.sp_target)));
//     // std::vector<double> wKCAPL_scales(n_compartments, 2 * ceil(-log(p.kc.sp_target)) / double(p.kc.N));

//     // Try sth new, differentially initializes the weight for different compartments
//     // TO BE REVIEWED
//     std::vector<double> wAPLKC_scales(n_compartments);
//     std::vector<double> wKCAPL_scales(n_compartments);
//     for (int comp = 0; comp < n_compartments; ++comp) {
//         double base = 2 * ceil(-log(p.kc.sp_target));
//         // Smaller jitter range
//         // file-local or function-static; not in a parallel block
//         static std::mt19937 rng(123456);
//         std::uniform_real_distribution<double> U(0.0, 1.0);
//         double jitter = 0.1 * base * U(rng);        
//         wAPLKC_scales[comp] = base + jitter;
//         wKCAPL_scales[comp] = (base + jitter) / double(p.kc.N);
//     }

//     // TO BE REVIEWED
//     // Apply initial compartment-specific weights into the full KC-wise vectors
//     for (unsigned kc = 0; kc < p.kc.N; ++kc) {
//         int comp = *kc_to_compartments[kc].begin();  // assume one compartment per KC for now 
//         rv.kc.wAPLKC(kc, 0) = wAPLKC_scales[comp];
//         rv.kc.wKCAPL(0, kc) = wKCAPL_scales[comp];
//     }
//     // TO BE REVIEWED
//     std::vector<std::vector<int>> compartment_kcs(n_compartments);
//     for (unsigned kc = 0; kc < p.kc.N; ++kc) {
//         if (!kc_to_compartments[kc].empty()) {
//             int comp = *kc_to_compartments[kc].begin();
//             compartment_kcs[comp].push_back(kc);
//         }  // assume one compartment per KC for now         compartment_kcs[comp].push_back(kc);
//     }


//     unsigned const TTFIXED = 1;
//     unsigned const TTHSTATIC = 2;
//     unsigned const TTMIXED = 3;
//     unsigned const TTUNIFORM = 4;
//     unsigned const TTINVALID = 5;
//     std::string tt = p.kc.thr_type;
//     bool nott = (tt == "");
//     unsigned thrtype =
//         nott ?
//             p.kc.use_fixed_thr ? TTFIXED :
//             p.kc.use_homeostatic_thrs ? TTHSTATIC :
//             TTUNIFORM
//         :   tt == "uniform" ? TTUNIFORM :
//             tt == "hstatic" ? TTHSTATIC :
//             tt == "mixed" ? TTMIXED :
//             tt == "fixed" ? TTFIXED :
//         (abort(), TTINVALID);

//     // stores the current measured sparsity (activity level) of Kenyon Cells (KCs) in each compartment
//     // used to adjust the inhibitory APL↔KC weights during the tuning loop to bring sparsity closer to a target.
//     std::vector<double> comp_sparsities(n_compartments, 0.0);

//     /* Break up into threads. */
// #pragma omp parallel
//     {
//         /* Output matrices for the KC simulation. */
//         Matrix Vm(p.kc.N, p.time.steps_all());
//         Matrix spikes(p.kc.N, p.time.steps_all());
//         Matrix nves(p.kc.N, p.time.steps_all());
//         Matrix inh(n_compartments, p.time.steps_all());
//         Matrix Is (n_compartments, p.time.steps_all());

//         // TODO delete (assuming i want this for use_vector_thr. why don't i for
//         // TTFIXED?)
//         // if (thrtype != TTFIXED && !p.kc.use_vector_thr) {
//         if (thrtype != TTFIXED && !p.kc.use_vector_thr) {
// #pragma omp single
//             {
//                 // TODO print str value for thrtype instead? (may need to add something
//                 // to invert mapping above. seems like some cases above currently don't
//                 // use the existing string p.kc.thr_type [but that could be changed?])
//                 rv.log(cat("choosing thresholds from spontaneous input (thrtype=",
//                            thrtype, ")"));
//             }

//             // TODO TODO maybe i still want to sim_KC_layer in use_vector_thr case
//             // (just not use it to v pick a thr)?

//             /* Measure voltages achieved by the KCs, and choose a threshold
//              * based on that. */
// #pragma omp for
//             for (unsigned i = 0; i < tlist.size(); i++) {
//                 sim_KC_layer(p, rv,
//                         rv.pn.sims[tlist[i]], rv.ffapl.vm_sims[tlist[i]],
//                         Vm, spikes, nves, inh, Is, KC_row);
// #pragma omp critical
//                 KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*2.0;
//             }

// #pragma omp single
//             {
//                 // TODO TODO need to redefine these after end of fit_sparseness
//                 // (so they are actually accurate and useful in mb_model's use to
//                 // compute per-subtype thresholds) (currently just hardcoding thresholds
//                 // rather than trying to compute them from pks in python)
//                 rv.kc.pks = KCpks;
//                 /*for (unsigned w = 0; w < rv.kc.pks.rows(); w++) {
//                     for (unsigned z = 0; z < rv.kc.pks.cols(); z++) {
//                         if (rv.kc.pks(w,z) < -1e20) abort();
//                     }
//                 }*/

//                 // TODO TODO make a new variable, like rv.kc.pks, but only set at the
//                 // end (so as to also include the APL's influence). store the same peak
//                 // KC Vms (or whatever exact quantity pks is)? (same thing comment above
//                 // is asking for, just into a new variable)

//                 /* Finish picking thresholds. */
//                 rv.kc.thr =
//                     (thrtype == TTHSTATIC ? choose_KC_thresh_homeostatic :
//                      thrtype == TTMIXED ? choose_KC_thresh_mixed :
//                      choose_KC_thresh_uniform)
//                     (p, KCpks, spont_in);
//                 // TODO TODO compute + log sparsity here? (from KCpks)
//                 // TODO + save into new rv variable, for use in al_analysis?
//                 // (even worth? i assume that w/ reasonable pre-conditions, we can
//                 // always get pretty bang-on here?)
//             }
//         }

//         // TODO if i move the stuff in this `#pragma omp single` block up enough, can i
//         // avoid need to switch back to single threaded? (without it here,
//         // `use_connectome_APL_weights=True` sensitivity analysis check repro-ing output
//         // w/ fixed wAPLKC/wKCAPL is failing, b/c crazy high values on output
//         // wAPLKC/etc)
// #pragma omp single
//         {
//         if (!p.kc.tune_apl_weights && p.kc.preset_wAPLKC) {
//             // TODO delete
//             rv.log(cat("FIXED rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

//             rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
//         }
//         if (!p.kc.tune_apl_weights && p.kc.preset_wKCAPL) {
//             // TODO delete
//             rv.log(cat("FIXED rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

//             rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
//         }
//         }

//         // TODO TODO in use_vector_thr=True case, want to at least log/save the
//         // mean response rate before APL (esp if rv.kc.thr not set appropriately there,
//         // which maybe could have been used in python to compute that?)

//         // TODO if `!tune_apl_weights` just return here, so i can de-ident code below?
//         // or does some or it need to run?
//         /* Enter this region only if APL use is enabled; if disabled, just exit
//          * (at this point APL->KC weights are set to 0). */
//         if (p.kc.tune_apl_weights) {
// #pragma omp single
//         {
//             rv.log(cat("tuning APL<->KC weights; tuning begin (",
//                         "target=", p.kc.sp_target,
//                         " acc=", p.kc.sp_acc,
//                         ")"));

//             rv.kc.tuning_iters = 1;
//             // TODO maybe require/assume input preset vectors will be normalized or
//             // scaled in a certain way? or compute appropriate w[APLKC|KCAPL]_scale
//             // constants to have mean (after multiplying by preset vectors) equal to
//             // what we would have been starting with before (maybe to average value of 1
//             // [this is what al_analysis is currently doing], so we can set *_scale
//             // factors to same as wAPLKC/wKCAPL being set below)?
//             /* Starting values for to-be-tuned APL<->KC weights. */
//             if (!p.kc.preset_wAPLKC) {
//                 // e.g. 3 w/ sp_target=0.1
//                 rv.kc.wAPLKC.setConstant(2*ceil(-log(p.kc.sp_target)));
//             } else {
//                 rv.kc.wAPLKC_scale = 2*ceil(-log(p.kc.sp_target));
//                 // TODO delete
//                 rv.log(cat("INITIAL rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

//                 rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
//             }
//             if (!p.kc.preset_wKCAPL) {
//                 rv.kc.wKCAPL.setConstant(2*ceil(-log(p.kc.sp_target)) / double(p.kc.N));
//             } else {
//                 rv.kc.wKCAPL_scale = 2*ceil(-log(p.kc.sp_target)) / double(p.kc.N);
//                 // TODO delete
//                 rv.log(cat("INITIAL rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

//                 rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
//             }
//             // TODO TODO have code fail (terminate w/o achieving target sp) [or
//             // backtrack somehow] if count of either changes (don't want to add 0s)
//             int n_wAPLKC_lte0_initial = (rv.kc.wAPLKC.array() <= 0.0).count();
//             int n_wKCAPL_lte0_initial = (rv.kc.wKCAPL.array() <= 0.0).count();
//             rv.log(cat("n_wAPLKC_lte0_initial: ", n_wAPLKC_lte0_initial));
//             rv.log(cat("n_wKCAPL_lte0_initial: ", n_wKCAPL_lte0_initial));

//             {
//                 std::ostringstream oss;
//                 oss << "test after compare: first 10 wAPLKC values: ";
//                 for (int i = 0; i < std::min<int>(10, rv.kc.wAPLKC.size()); ++i) {
//                     oss << rv.kc.wAPLKC(i) << " ";
//                 }
//                 rv.log(oss.str());
//             }

//             {
//                 std::ostringstream oss;
//                 oss << "test after compare: first 10 wKCAPL values: ";
//                 for (int i = 0; i < std::min<int>(10, rv.kc.wKCAPL.size()); ++i) {
//                     oss << rv.kc.wKCAPL(i) << " ";
//                 }
//                 rv.log(oss.str());
//             }
//         }
        

//         std::vector<bool> converged(n_compartments, false);
//         /* Continue tuning until we reach the desired sparsity. */
//         while(true) { // the tuning loop! 
//             //rv.log(cat("** t", omp_get_thread_num(), " @ top"));
//             KCmean_st.setZero(); // FOR SPARSITY CHECK
//             // std::fill(comp_sparsities.begin(), comp_sparsities.end(), 0.0); // FOR SPARSITY CHECK

// #pragma omp barrier

// #pragma omp for
//             for (unsigned i = 0; i < tlist.size(); i+=p.kc.apltune_subsample) {
//                 sim_KC_layer(p, rv,
//                         rv.pn.sims[tlist[i]], rv.ffapl.vm_sims[tlist[i]],
//                         Vm, spikes, nves, inh, Is, KC_row);
//                 KCmean_st.col(i / p.kc.apltune_subsample)  = spikes.rowwise().sum();

// //#pragma omp critical
//                 // TODO delete?
//                 ////KCpks.col(i) = Vm.rowwise().maxCoeff(); // - spont_in*2.0;
//                 // TODO probably restore
//                 //KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*2.0;
//                 ////KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*10.0;
//             }

// #pragma omp single
//             {
//                 /* Modify the APL<->KC weights in order to move in the
//                  * direction of the target sparsity. */

//                 //double lr = p.kc.sp_lr_coeff / (1.0 + double(rv.kc.tuning_iters)); // CHECK
//                 double lr = p.kc.sp_lr_coeff / sqrt(double(rv.kc.tuning_iters)); 

//                 /* 
//                 Old implementation
//                 double delta = (sp - p.kc.sp_target) * lr / p.kc.sp_target;
//                 // TODO log initial value of delta?

//                 // TODO TODO TODO try to come up w/ an equiv calc that preserves
//                 // behavior in old case, but also works w/ new vector wAPLKC/wKCAPL?
//                 // TODO TODO maybe store initial values in separate vectors (for
//                 // preset_* = true cases), then just change scale here (rather than
//                 // `+=`)?
//                 if (!p.kc.preset_wAPLKC) {
//                     // TODO why using .array() for +=, but not for direct assignment
//                     // operations? is .array() actually necessary in this case?
//                     // what does .array() do?
//                     rv.kc.wAPLKC.array() += delta;
//                 } else {
//                     rv.kc.wAPLKC_scale += delta;

//                     // TODO delete?
//                     rv.log(cat("rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

//                     rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
//                 }

//                 if (!p.kc.preset_wKCAPL) {
//                     rv.kc.wKCAPL.array() += delta / double(p.kc.N);
//                 } else {
//                     rv.kc.wKCAPL_scale += delta / double(p.kc.N);

//                     // TODO delete?
//                     rv.log(cat("rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

//                     rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
//                 }
//                 */

//                 // Compute per-compartment sparsities 
//                 // TO BE REVIEWED
//                 // Binarize all KC responses to 0/1
//                 KCmean_st = (KCmean_st.array() > 0.0).cast<double>();


//                 // Then compute each compartment’s sparsity
//                 for (int comp = 0; comp < n_compartments; ++comp) {
//                     double sum = 0.0;
//                     for (int kc : compartment_kcs[comp]) {
//                         // Now row(kc).mean() is the fraction of odors in which KC 'kc' fired
//                         sum += KCmean_st.row(kc).mean();
//                     }
//                     comp_sparsities[comp] = sum / compartment_kcs[comp].size();
//                 }
                
            

//                 // Update scalars for each compartment
//                 // TO BE REVIEWED
//                 for (int comp = 0; comp < n_compartments; ++comp) {
//                     /* single delta method 
//                     double delta = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;

//                     wAPLKC_scales[comp] += delta;
//                     wKCAPL_scales[comp] += delta / double(p.kc.N);
//                     */
                    
//                     // per compartmental delta method
//                     if (converged[comp]) continue;

//                     double delta = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;
//                     double delta_apl_kc = delta;
//                     double n_comp_kcs = double(compartment_kcs[comp].size()); 
//                     // double delta_kc_apl = delta / double(p.kc.N); 
//                     double delta_kc_apl = delta / n_comp_kcs;  // divide by number of KCs in that compartment? 


//                     wAPLKC_scales[comp] += delta_apl_kc;
//                     wKCAPL_scales[comp] += delta_kc_apl;
//                 }

//                 // Push updated scalars into rv.kc weight vectors
//                 for (unsigned kc = 0; kc < p.kc.N; ++kc) {
//                     int comp = *kc_to_compartments[kc].begin();
//                     rv.kc.wAPLKC(kc, 0) = wAPLKC_scales[comp];
//                     rv.kc.wKCAPL(0, kc) = wKCAPL_scales[comp];
//                 }


//                 /*per compartmental delta method*/
//                 rv.log(cat("* i=", rv.kc.tuning_iters, ", lr=", lr));
//                 for (int comp = 0; comp < n_compartments; ++comp) {
//                     double delta_A = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;
//                     double delta_K = delta_A / double(p.kc.N);
//                     std::ostringstream comp_s;
//                     comp_s << std::fixed << std::setprecision(4) << comp_sparsities[comp];
//                     rv.log(cat("  Comp ", comp,
//                             " | sp=", comp_s.str(),
//                             " | delta_A=", delta_A,
//                             " | delta_K=", delta_K,
//                             " | scale_A=", wAPLKC_scales[comp],
//                             " | scale_K=", wKCAPL_scales[comp]));
//                 }

//                 // TODO delete
//                 // for debugging + trying to support scaling of arbitrary positive
//                 // vector wAPLKC/wKCAPL inputs
//                 if (p.kc.preset_wAPLKC) {
//                     // collect unique APL→KC scales
//                     std::set<double> uniqA;
//                     for (int i = 0; i < rv.kc.wAPLKC.rows(); ++i)
//                         uniqA.insert(rv.kc.wAPLKC(i, 0));

//                     // build a string of the uniques
//                     std::ostringstream ossA;
//                     ossA << "wAPLKC unique scales: ";
//                     for (double v : uniqA)
//                         ossA << v << " ";
//                     rv.log(ossA.str());
//                 }

//                 if (p.kc.preset_wKCAPL) {
//                     // collect unique KC→APL scales
//                     std::set<double> uniqK;
//                     for (int i = 0; i < rv.kc.wKCAPL.cols(); ++i)
//                         uniqK.insert(rv.kc.wKCAPL(0, i));

//                     std::ostringstream ossK;
//                     ossK << "wKCAPL unique scales: ";
//                     for (double v : uniqK)
//                         ossK << v << " ";
//                     rv.log(ossK.str());
//                 }
//                 // if (p.kc.preset_wAPLKC) {
//                 //     // collect unique APL→KC scales
//                 //     std::set<double> uniqA;
//                 //     for (int i = 0; i < rv.kc.wAPLKC.rows(); ++i)
//                 //         uniqA.insert(rv.kc.wAPLKC(i, 0));

//                 //     // log only the count of unique scales
//                 //     std::ostringstream ossA;
//                 //     ossA << "number of unique wAPLKC scales: " << uniqA.size();
//                 //     rv.log(ossA.str());
//                 // }

//                 // if (p.kc.preset_wKCAPL) {
//                 //     // collect unique KC→APL scales
//                 //     std::set<double> uniqK;
//                 //     for (int i = 0; i < rv.kc.wKCAPL.cols(); ++i)
//                 //         uniqK.insert(rv.kc.wKCAPL(0, i));

//                 //     // log only the count of unique scales
//                 //     std::ostringstream ossK;
//                 //     ossK << "number of unique wKCAPL scales: " << uniqK.size();
//                 //     rv.log(ossK.str());
//                 // }



//                 rv.kc.tuning_iters++;
//             }

//             //rv.log(cat("** t", omp_get_thread_num(), " @ before testing"));
//             /* Run through a bunch of odors to test sparsity. */

// /* test: move this loop before wAPLKC calculation*/
// // #pragma omp for
// //             for (unsigned i = 0; i < tlist.size(); i+=p.kc.apltune_subsample) {
// //                 sim_KC_layer(p, rv,
// //                         rv.pn.sims[tlist[i]], rv.ffapl.vm_sims[tlist[i]],
// //                         Vm, spikes, nves, inh, Is);
// //                 KCmean_st.col(i / p.kc.apltune_subsample)  = spikes.rowwise().sum();

// // //#pragma omp critical
// //                 // TODO delete?
// //                 ////KCpks.col(i) = Vm.rowwise().maxCoeff(); // - spont_in*2.0;
// //                 // TODO probably restore
// //                 //KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*2.0;
// //                 ////KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*10.0;
// //             }
           

//             //rv.log(cat("** t", omp_get_thread_num(), " @ after testing"));

// #pragma omp single
//             {
//                 // TODO delete
//                 //rv.log(cat("KCpks.mean(): ", KCpks.mean()));
//                 //rv.log(cat("spont_in.mean(): ", spont_in.mean()));
//                 //
//                 // TODO restore? (+ fix surrounding) (or probably better set, set
//                 // post-APL peaks into new rv.kc variable...)
//                 // don't think i could use same way as i do for prior pks [which I use
//                 // in python to set thresholds, in a similar manner to how they are used
//                 // in here] tho, so might be pointless.
//                 // more complicated by this point, since also depend on activity of all
//                 // other KCs, so don't think i can as easily use to set e.g. a single
//                 // KC's APL weights.
//                 //rv.kc.pks = KCpks;

//                 KCmean_st = (KCmean_st.array() > 0.0).select(1.0, KCmean_st);
//                 sp = KCmean_st.mean();
//                  double active_kcs = KCmean_st.sum();
//                 rv.log(cat("Iteration ", rv.kc.tuning_iters, " | Total active KCs: ", active_kcs));

//                  // Binarize responses
                    
            
//                 // Reset per-compartment sparsity accumulators
//                 std::fill(comp_sparsities.begin(), comp_sparsities.end(), 0.0);  // FOR SPARSITY CHECK
            
//                 // Compute new sparsities
//                 for (int comp = 0; comp < n_compartments; ++comp) {
//                     double sum = 0.0;
//                     for (int kc : compartment_kcs[comp]){
//                         sum += KCmean_st.row(kc).mean();
//                         comp_sparsities[comp] = sum / compartment_kcs[comp].size();
//                     }
//                 }
//             }
            
//             // format global sparsity to 4 decimal places
//             std::ostringstream sp_ss;
//             sp_ss << std::fixed << std::setprecision(4) << sp;

//             rv.log(cat("** t", omp_get_thread_num(),
//                     " @ before bottom cond [",
//                     "sp=", sp_ss.str(),
//                     ", i=", rv.kc.tuning_iters,
//                     ", tgt=", p.kc.sp_target,
//                     ", acc=", p.kc.sp_acc,
//                     ", I=", p.kc.max_iters,
//                     "]"));

//         // logic if calculating per compartmental deltas
//         int n_converged = 0;
//         for (int comp = 0; comp < n_compartments; ++comp) {
//             double rel_diff = std::abs(comp_sparsities[comp] - p.kc.sp_target) / p.kc.sp_target;
//             if (rel_diff <= p.kc.sp_acc) {
//                 converged[comp] = true;
//                 n_converged++;
//             }
//         }
//         if (n_converged == n_compartments) {
//             rv.log("All compartments converged!");
//             break;
//         }
//         if (rv.kc.tuning_iters > p.kc.max_iters) {
//             rv.log("WARNING: Max iterations reached. Some compartments may not have converged.");
//             break;
//         }
//         // two deltas method
//         } 
        
//         // original single delta method
//         // while ((abs(sp - p.kc.sp_target) > (p.kc.sp_acc * p.kc.sp_target))
//         //         && (rv.kc.tuning_iters <= p.kc.max_iters)); 
//         //rv.log(cat("** t", omp_get_thread_num(), " @ exit"));
// #pragma omp barrier
// #pragma omp single
//         {
//             rv.kc.tuning_iters--;
//         }
//     }}

//     // Declare exactly the same temporaries used inside the tuner:
//     Matrix Vm_end(p.kc.N,    p.time.steps_all());
//     Matrix spikes_end(p.kc.N, p.time.steps_all());
//     Matrix nves_end(p.kc.N,   p.time.steps_all());
//     Row inh_end(n_compartments, p.time.steps_all()), Is_end(n_compartments, p.time.steps_all());

//     // Build a response matrix exactly as in the tuning loop: one column per subsampled odor
//     unsigned nCols = 1 + ((tlist.size() - 1) / p.kc.apltune_subsample);
//     Matrix resp(p.kc.N, nCols);

//     for (unsigned i = 0; i < tlist.size(); i += p.kc.apltune_subsample) {
//         // run a KC sim exactly as you do above
//         sim_KC_layer(p, rv,
//             rv.pn.sims[tlist[i]],
//             rv.ffapl.vm_sims[tlist[i]],
//             Vm_end, spikes_end, nves_end, inh_end, Is_end, KC_row);

//             // sum across time, then binarize  
//         resp.col(i / p.kc.apltune_subsample) =
//             (spikes_end.rowwise().sum().array() > 0.0).cast<double>();
//     }
 
//     double overallS = resp.mean();
//     rv.log(cat("Overall sparsity after tuning: ", overallS));

//     // TODO always log tuned parameters at end (fixed_thr, wAPLKC/wKCAPL when not
//     // preset, or wAPLKC_scale/wKCAPL_scale when preset)
//     rv.log("done fitting sparseness");
// }


// This version of fit_sparseness_claw calculates sparsity using KC activation
// void fit_sparseness_claw(ModelParams const& p, RunVars& rv, bool KC_row) {
//     rv.log("test fit_sparseness_claw");

//     std::vector<unsigned> tlist = p.kc.tune_from;
//     if (!tlist.size()) {
//         for (unsigned i = 0; i < get_nodors(p); i++) tlist.push_back(i);
//     }

//     /* Calculate spontaneous input to KCs. */
//     // TODO log stuff about PN spont to figure out if part of that isn't init'd
//     // properly?
//     Column spont_in = rv.kc.wPNKC * sample_PN_spont(p, rv);
//     rv.kc.spont_in = spont_in;

    
//     // declare wAPLKC and wKCAPL with size of claws instead of number of KCs
//     unsigned num_claws = rv.kc.claw_to_kc.size();
//     rv.log(cat("number of claws: ", num_claws)); // claw number is correct 
//     // BEFORE any resize, capture the preset vectors if present
//     Column preset_wAPLKC_KC;   // expected shape: (p.kc.N, 1) if per-KC
//     Row    preset_wKCAPL_KC;   // expected shape: (1, p.kc.N)

//     if (p.kc.preset_wAPLKC) {
//         preset_wAPLKC_KC = rv.kc.wAPLKC;   // deep copy of whatever Python set
//     }
//     if (p.kc.preset_wKCAPL) {
//         preset_wKCAPL_KC = rv.kc.wKCAPL;   // deep copy
//     }

//     // Now resize claw-wise containers and ZERO them to avoid UB
//     rv.kc.wAPLKC.resize(num_claws, 1);
//     rv.kc.wAPLKC.setZero();
//     rv.kc.wKCAPL.resize(1, num_claws);
//     rv.kc.wKCAPL.setZero();

//     // Build unscaled per-CLAW presets deterministically
//     Column wAPLKC_unscaled(num_claws, 1); wAPLKC_unscaled.setOnes();  // default 1s
//     Row    wKCAPL_unscaled(1, num_claws); wKCAPL_unscaled.setOnes();

//     if (p.kc.preset_wAPLKC) {
//         // If the preset was per-KC length N, expand to claws using claw_to_kc
//         if (preset_wAPLKC_KC.rows() == (Eigen::Index)p.kc.N && preset_wAPLKC_KC.cols() == 1) {
//             for (unsigned claw = 0; claw < num_claws; ++claw) {
//                 unsigned kc = rv.kc.claw_to_kc[claw];
//                 wAPLKC_unscaled(claw, 0) = preset_wAPLKC_KC(kc, 0);
//             }
//         } else if (preset_wAPLKC_KC.rows() == (Eigen::Index)num_claws && preset_wAPLKC_KC.cols() == 1) {
//             // already per-claw
//             wAPLKC_unscaled = preset_wAPLKC_KC;
//         } else {
//             rv.log("ERROR: preset_wAPLKC has unexpected shape; falling back to ones.");
//         }
//     }

//     if (p.kc.preset_wKCAPL) {
//         if (preset_wKCAPL_KC.rows() == 1 && preset_wKCAPL_KC.cols() == (Eigen::Index)p.kc.N) {
//             for (unsigned claw = 0; claw < num_claws; ++claw) {
//                 unsigned kc = rv.kc.claw_to_kc[claw];
//                 wKCAPL_unscaled(0, claw) = preset_wKCAPL_KC(0, kc);
//             }
//         } else if (preset_wKCAPL_KC.rows() == 1 && preset_wKCAPL_KC.cols() == (Eigen::Index)num_claws) {
//             wKCAPL_unscaled = preset_wKCAPL_KC;
//         } else {
//             rv.log("ERROR: preset_wKCAPL has unexpected shape; falling back to ones.");
//         }
//     }


//     // TODO do i actually need these vars? don't i still want to assign scaled
//     // wAPLKC/wKCAPL vectors into rv.kc.wAPLKC/wKCAPL at the end
//     /* Should only be used in preset_w[APLKC|KCAPL] = true cases */
    

//     /* Set starting values for the things we'll tune. */
//     // TODO matter? seems to be overwritten below in this case anyway...
//     // (and put inside this conditional to avoid overwriting values set in python, via
//     // pybind11)
//     if (p.kc.tune_apl_weights) {
//         if (!p.kc.preset_wAPLKC) {
//             rv.kc.wAPLKC.setZero();
//         }
//         if (!p.kc.preset_wKCAPL) {
//             rv.kc.wKCAPL.setConstant(1.0/float(num_claws));
//         }
//     }

//     // print tests: 
//     {
//         std::ostringstream oss;
//         oss << "test after zero: first 10 wAPLKC values: ";
//         for (int i = 0; i < std::min<int>(10, rv.kc.wAPLKC.size()); ++i) {
//             oss << rv.kc.wAPLKC(i) << " ";
//         }
//         rv.log(oss.str());
//     }

//     {
//         std::ostringstream oss;
//         oss << "test after zero: first 10 wKCAPL values: ";
//         for (int i = 0; i < std::min<int>(10, rv.kc.wKCAPL.size()); ++i) {
//             oss << rv.kc.wKCAPL(i) << " ";
//         }
//         rv.log(oss.str());
//     }

//     // TODO check that, in NOT p.kc.tune_apl_weights case, wAPLKC and wKCAPL are
//     // appropriately initialized? maybe also in preset_wAPLKC/preset_wKCAPL = true
//     // cases above?

//     if (!p.kc.use_vector_thr) {
//         if (!p.kc.use_fixed_thr) {
//             rv.kc.thr.setConstant(1e5); // higher than will ever be reached
//         }
//         else {
//             rv.log(cat("using FIXED threshold: ", p.kc.fixed_thr));
//             // TODO would it ever make sense to have add_fixed_thr_to_spont=False?
//             // when? in any cases i use? doc
//             if (p.kc.add_fixed_thr_to_spont) {
//                 // TODO delete + replace w/ similar commented line below
//                 // (after confirming the 2 things w/ factor 2 cancel out...)
//                 rv.log("adding fixed threshold to 2 * spontaneous PN input to each KC");
//                 //rv.log("adding fixed threshold to spontaneous PN input to each KC");
//                 // TODO TODO what are units of spont_in? doc these as units of fixed_thr
//                 rv.kc.thr = p.kc.fixed_thr + spont_in.array()*2.0;
//             } else {
//                 rv.kc.thr.setConstant(p.kc.fixed_thr);
//             }
//         }
//     } else {
//         rv.log("using prespecified vector KC thresholds");
//         // TODO even want to allow `add_fixed_thr_to_spont = False`? don't think it's
//         // useful now
//         if (p.kc.add_fixed_thr_to_spont) {
//             rv.log("adding threshold to 2 * spontaneous PN input to each KC");

//             // TODO delete
//             // TODO do i need .array() here? also, i assuming changing <x>.array() also
//             // changes values in <x> (assuming it's a Matrix/similar)?
//             rv.log(cat("(before adding spont) rv.kc.thr.mean(): ", rv.kc.thr.mean()));

//             // TODO this line working as intended? (do need LHS .array() to avoid err,
//             // at least w/ RHS as it is here)
//             rv.kc.thr.array() += spont_in.array()*2.0;

//             // TODO delete
//             // TODO do i need .array() here?
//             rv.log(cat("(after adding spont) rv.kc.thr.mean(): ", rv.kc.thr.mean()));
//         }
//     }

//     /* Used for measuring KC voltage; defined here to make it shared across all
//      * threads.*/
//     Matrix KCpks(p.kc.N, tlist.size()); KCpks.setZero();

//     /* Used to store odor response data during APL tuning. */
//     Matrix KCmean_st(p.kc.N, 1+ ((tlist.size() - 1) / p.kc.apltune_subsample));
//     // TODO TODO should this not be computed on first iteration?
//     /* Used to store the current sparsity.
//      * Initially set to the below value because, given default model
//      * parameters, it causes tuning to complete in just one iteration. */
//     double sp = 0.0789;
//     /* Used to count number of times looped; the 'learning rate' is decreased
//      * as 1/sqrt(count) with each iteration. */
//     rv.kc.tuning_iters = 0;

//     int n_compartments = rv.kc.claw_compartments.maxCoeff() + 1;

//     // TO BE REVIEWED
//     // Map each KC to the set of compartments it has claws in
//     // compartment_claws; for each compartment, it has the index of claws that it contains?
     
//     // Initialize per-compartment APL↔KC weight scalars
//     // std::vector<double> wAPLKC_scales(n_compartments, 2 * ceil(-log(p.kc.sp_target)));
//     // std::vector<double> wKCAPL_scales(n_compartments, 2 * ceil(-log(p.kc.sp_target)) / double(p.kc.N));

//     // Try sth new, differentially initializes the weight for different compartments
//     // TO BE REVIEWED
//     std::vector<double> wAPLKC_scales(n_compartments);
//     std::vector<double> wKCAPL_scales(n_compartments);
//     for (int comp = 0; comp < n_compartments; ++comp) {
//         double base = 2 * ceil(-log(p.kc.sp_target));
//         // file-local or function-static; not in a parallel block
//         static std::mt19937 rng(123456);
//         std::uniform_real_distribution<double> U(0.0, 1.0);
//         double jitter = 0.1 * base * U(rng);
//         wAPLKC_scales[comp] = base + jitter;
//         wKCAPL_scales[comp] = (base + jitter) / double(num_claws); 
//     }

//     // TO BE REVIEWED
//     // Apply initial compartment-specific weights into the full claw-wise vectors
//     for (unsigned claw = 0; claw < num_claws; ++claw) {
//         int comp = rv.kc.claw_compartments(claw);
//         rv.kc.wAPLKC(claw, 0) = wAPLKC_scales[comp];
//         rv.kc.wKCAPL(0, claw) = wKCAPL_scales[comp];
//     }


//     // print tests: 
//     {
//         std::ostringstream oss;
//         oss << "test after initialization: first 10 wAPLKC values: ";
//         for (int i = 0; i < std::min<int>(10, rv.kc.wAPLKC.size()); ++i) {
//             oss << rv.kc.wAPLKC(i) << " ";
//         }
//         rv.log(oss.str());
//     }

//     {
//         std::ostringstream oss;
//         oss << "test after initialization: first 10 wKCAPL values: ";
//         for (int i = 0; i < std::min<int>(10, rv.kc.wKCAPL.size()); ++i) {
//             oss << rv.kc.wKCAPL(i) << " ";
//         }
//         rv.log(oss.str());
//     }

//     std::vector<int> comp_claw_count(n_compartments, 0);
//     for (Eigen::Index claw = 0; claw < rv.kc.claw_to_kc.size(); ++claw) {
//         int comp = rv.kc.claw_compartments(claw);
//         if (comp >= 0 && comp < n_compartments) comp_claw_count[comp]++;
//     }
//     //printf("comp_claw_count[0] = %d\n", comp_claw_count[0]);
//     //printf("comp_claw_count[1] = %d\n", comp_claw_count[1]);
//     //int n_compartments = rv.kc.claw_compartments.maxCoeff() + 1;

//     // Map each KC to its compartments:
//     std::vector<std::unordered_set<int>> kc_to_compartments(p.kc.N);
//     for (Eigen::Index claw = 0; claw < rv.kc.claw_to_kc.size(); ++claw) {
//         unsigned kc = rv.kc.claw_to_kc[claw];
//         int comp    = rv.kc.claw_compartments(claw);
//         if (0 <= comp && comp < n_compartments) {
//             kc_to_compartments[kc].insert(comp);
//         } else {
//             assert(false && "claw_compartments out of range");
//         }
//     }
//     // TO BE REVIEWED
//     std::vector<std::vector<int>> compartment_kcs(n_compartments);
//     for (unsigned kc = 0; kc < p.kc.N; ++kc) {
//         if (!kc_to_compartments[kc].empty()) {
//             int comp = *kc_to_compartments[kc].begin();
//             compartment_kcs[comp].push_back(kc);
//         }  // assume one compartment per KC for now 
//     }

//     // std::vector<std::vector<int>> compartment_kcs(n_compartments);
//     // for (unsigned kc = 0; kc < p.kc.N; ++kc) {
//     //     const auto& comps = kc_to_compartments[kc];
//     //     if (!comps.empty()) {
//     //         int chosen = *std::min_element(comps.begin(), comps.end()); // stable rule
//     //         compartment_kcs[chosen].push_back(kc);
//     //     }
//     // }
//     // // (optional) sort for a stable KC order inside each compartment:
//     // for (auto& v : compartment_kcs) std::sort(v.begin(), v.end());



//     unsigned const TTFIXED = 1;
//     unsigned const TTHSTATIC = 2;
//     unsigned const TTMIXED = 3;
//     unsigned const TTUNIFORM = 4;
//     unsigned const TTINVALID = 5;
//     std::string tt = p.kc.thr_type;
//     bool nott = (tt == "");
//     unsigned thrtype =
//         nott ?
//             p.kc.use_fixed_thr ? TTFIXED :
//             p.kc.use_homeostatic_thrs ? TTHSTATIC :
//             TTUNIFORM
//         :   tt == "uniform" ? TTUNIFORM :
//             tt == "hstatic" ? TTHSTATIC :
//             tt == "mixed" ? TTMIXED :
//             tt == "fixed" ? TTFIXED :
//         (abort(), TTINVALID);

//     // stores the current measured sparsity (activity level) of Kenyon Cells (KCs) in each compartment
//     // used to adjust the inhibitory APL↔KC weights during the tuning loop to bring sparsity closer to a target.
//     std::vector<double> comp_sparsities(n_compartments, 0.0);

//     /* Break up into threads. */
// #pragma omp parallel
//     {
//         /* Output matrices for the KC simulation. */
//         Matrix Vm(p.kc.N, p.time.steps_all());
//         Matrix spikes(p.kc.N, p.time.steps_all());
//         Matrix nves(p.kc.N, p.time.steps_all());
//         Matrix inh(n_compartments, p.time.steps_all());
//         Matrix Is (n_compartments, p.time.steps_all());

//         // TODO delete (assuming i want this for use_vector_thr. why don't i for
//         // TTFIXED?)
//         // if (thrtype != TTFIXED && !p.kc.use_vector_thr) {

//         // print tests: 
//         // {
//         //     std::ostringstream oss;
//         //     oss << "test before sim_KC_layer: first 10 wAPLKC values: ";
//         //     for (int i = 0; i < std::min<int>(10, rv.kc.wAPLKC.size()); ++i) {
//         //         oss << rv.kc.wAPLKC(i) << " ";
//         //     }
//         //     rv.log(oss.str());
//         // }

//         // {
//         //     std::ostringstream oss;
//         //     oss << "test before sim_KC_layer: first 10 wKCAPL values: ";
//         //     for (int i = 0; i < std::min<int>(10, rv.kc.wKCAPL.size()); ++i) {
//         //         oss << rv.kc.wKCAPL(i) << " ";
//         //     }
//         //     rv.log(oss.str());
//         // }

//         if (thrtype != TTFIXED && !p.kc.use_vector_thr) {
// #pragma omp single
//             {
//                 // TODO print str value for thrtype instead? (may need to add something
//                 // to invert mapping above. seems like some cases above currently don't
//                 // use the existing string p.kc.thr_type [but that could be changed?])
//                 rv.log(cat("choosing thresholds from spontaneous input (thrtype=",
//                            thrtype, ")"));
//             }

//             // TODO TODO maybe i still want to sim_KC_layer in use_vector_thr case
//             // (just not use it to v pick a thr)?

//             /* Measure voltages achieved by the KCs, and choose a threshold
//              * based on that. */
// #pragma omp for
//             for (unsigned i = 0; i < tlist.size(); i++) {
//                 sim_KC_layer(p, rv,
//                         rv.pn.sims[tlist[i]], rv.ffapl.vm_sims[tlist[i]],
//                         Vm, spikes, nves, inh, Is, KC_row);
// #pragma omp critical
//                 KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*2.0;
//             }

// #pragma omp single
//             {
//                 // TODO TODO need to redefine these after end of fit_sparseness
//                 // (so they are actually accurate and useful in mb_model's use to
//                 // compute per-subtype thresholds) (currently just hardcoding thresholds
//                 // rather than trying to compute them from pks in python)
//                 rv.kc.pks = KCpks;
//                 /*for (unsigned w = 0; w < rv.kc.pks.rows(); w++) {
//                     for (unsigned z = 0; z < rv.kc.pks.cols(); z++) {
//                         if (rv.kc.pks(w,z) < -1e20) abort();
//                     }
//                 }*/

//                 // TODO TODO make a new variable, like rv.kc.pks, but only set at the
//                 // end (so as to also include the APL's influence). store the same peak
//                 // KC Vms (or whatever exact quantity pks is)? (same thing comment above
//                 // is asking for, just into a new variable)

//                 /* Finish picking thresholds. */
//                 rv.kc.thr =
//                     (thrtype == TTHSTATIC ? choose_KC_thresh_homeostatic :
//                      thrtype == TTMIXED ? choose_KC_thresh_mixed :
//                      choose_KC_thresh_uniform)
//                     (p, KCpks, spont_in);
//                 // TODO TODO compute + log sparsity here? (from KCpks)
//                 // TODO + save into new rv variable, for use in al_analysis?
//                 // (even worth? i assume that w/ reasonable pre-conditions, we can
//                 // always get pretty bang-on here?)
//             }
//         }

//         // TODO if i move the stuff in this `#pragma omp single` block up enough, can i
//         // avoid need to switch back to single threaded? (without it here,
//         // `use_connectome_APL_weights=True` sensitivity analysis check repro-ing output
//         // w/ fixed wAPLKC/wKCAPL is failing, b/c crazy high values on output
//         // wAPLKC/etc)
// #pragma omp single
//         {
//         if (!p.kc.tune_apl_weights && p.kc.preset_wAPLKC) {
//             // TODO delete
//             rv.log(cat("FIXED rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

//             rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
//         }
//         if (!p.kc.tune_apl_weights && p.kc.preset_wKCAPL) {
//             // TODO delete
//             rv.log(cat("FIXED rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

//             rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
//         }
//         }

//         // TODO TODO in use_vector_thr=True case, want to at least log/save the
//         // mean response rate before APL (esp if rv.kc.thr not set appropriately there,
//         // which maybe could have been used in python to compute that?)

//         // TODO if `!tune_apl_weights` just return here, so i can de-ident code below?
//         // or does some or it need to run?
//         /* Enter this region only if APL use is enabled; if disabled, just exit
//          * (at this point APL->KC weights are set to 0). */
//         if (p.kc.tune_apl_weights) {
// #pragma omp single
//         {
//             rv.log(cat("tuning APL<->KC weights; tuning begin (",
//                         "target=", p.kc.sp_target,
//                         " acc=", p.kc.sp_acc,
//                         ")"));

//             rv.kc.tuning_iters = 1;
//             // TODO maybe require/assume input preset vectors will be normalized or
//             // scaled in a certain way? or compute appropriate w[APLKC|KCAPL]_scale
//             // constants to have mean (after multiplying by preset vectors) equal to
//             // what we would have been starting with before (maybe to average value of 1
//             // [this is what al_analysis is currently doing], so we can set *_scale
//             // factors to same as wAPLKC/wKCAPL being set below)?
//             /* Starting values for to-be-tuned APL<->KC weights. */
//             if (!p.kc.preset_wAPLKC) {
//                 // e.g. 3 w/ sp_target=0.1
//                 rv.kc.wAPLKC.setConstant(2*ceil(-log(p.kc.sp_target)));
//             } else {
//                 rv.kc.wAPLKC_scale = 2*ceil(-log(p.kc.sp_target));
//                 // TODO delete
//                 rv.log(cat("INITIAL rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));

//                 rv.kc.wAPLKC = rv.kc.wAPLKC_scale * wAPLKC_unscaled;
//             }
//             if (!p.kc.preset_wKCAPL) {
//                 rv.kc.wKCAPL.setConstant(2*ceil(-log(p.kc.sp_target)) / double(num_claws)); // to be honest, should this be divide by num_claw per compartment? 
//             } else {
//                 rv.kc.wKCAPL_scale = 2*ceil(-log(p.kc.sp_target)) / double(num_claws);
//                 // TODO delete
//                 rv.log(cat("INITIAL rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

//                 rv.kc.wKCAPL = rv.kc.wKCAPL_scale * wKCAPL_unscaled;
//             }
//             // TODO TODO have code fail (terminate w/o achieving target sp) [or
//             // backtrack somehow] if count of either changes (don't want to add 0s)
//             int n_wAPLKC_lte0_initial = (rv.kc.wAPLKC.array() <= 0.0).count();
//             int n_wKCAPL_lte0_initial = (rv.kc.wKCAPL.array() <= 0.0).count();
//             rv.log(cat("n_wAPLKC_lte0_initial: ", n_wAPLKC_lte0_initial));
//             rv.log(cat("n_wKCAPL_lte0_initial: ", n_wKCAPL_lte0_initial));
//             // rv.kc.wAPLKC.setConstant(4.15e-315);
//             // rv.kc.wKCAPL.setConstant(4.15e-318);
//             // print tests: 
//             {
//                 std::ostringstream oss;
//                 oss << "test after compare: first 10 wAPLKC values: ";
//                 for (int i = 0; i < std::min<int>(10, rv.kc.wAPLKC.size()); ++i) {
//                     oss << rv.kc.wAPLKC(i) << " ";
//                 }
//                 rv.log(oss.str());
//             }

//             {
//                 std::ostringstream oss;
//                 oss << "test after compare: first 10 wKCAPL values: ";
//                 for (int i = 0; i < std::min<int>(10, rv.kc.wKCAPL.size()); ++i) {
//                     oss << rv.kc.wKCAPL(i) << " ";
//                 }
//                 rv.log(oss.str());
//             }
//             rv.log(cat("test after compare wAPLKC: ", rv.kc.wAPLKC.mean()));
//             rv.log(cat("test after compare wKCAPL: ", rv.kc.wKCAPL.mean()));
//             rv.log(cat("threshold mean: ", rv.kc.thr.mean()));



//         }
        

//         std::vector<bool> converged(n_compartments, false);
//         /* Continue tuning until we reach the desired sparsity. */
//         while(true) { // the tuning loop! 
//             //rv.log(cat("** t", omp_get_thread_num(), " @ top"));
//             KCmean_st.setZero(); // FOR SPARSITY CHECK
//             // std::fill(comp_sparsities.begin(), comp_sparsities.end(), 0.0); // FOR SPARSITY CHECK

// #pragma omp barrier

// #pragma omp for
//             for (unsigned i = 0; i < tlist.size(); i+=p.kc.apltune_subsample) {
//                 sim_KC_layer(p, rv,
//                         rv.pn.sims[tlist[i]], rv.ffapl.vm_sims[tlist[i]],
//                         Vm, spikes, nves, inh, Is, KC_row);
//                 KCmean_st.col(i / p.kc.apltune_subsample)  = spikes.rowwise().sum();

// //#pragma omp critical
//                 // TODO delete?
//                 ////KCpks.col(i) = Vm.rowwise().maxCoeff(); // - spont_in*2.0;
//                 // TODO probably restore
//                 //KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*2.0;
//                 ////KCpks.col(i) = Vm.rowwise().maxCoeff() - spont_in*10.0;
//             }

// #pragma omp single
//             {
//                 /* Modify the APL<->KC weights in order to move in the
//                  * direction of the target sparsity. */

//                 //double lr = p.kc.sp_lr_coeff / (1.0 + double(rv.kc.tuning_iters)); // CHECK
//                 double lr = p.kc.sp_lr_coeff_cl / sqrt(double(rv.kc.tuning_iters)); 

                

//                 // Compute per-compartment sparsities 
//                 // TO BE REVIEWED
//                 // Binarize all KC responses to 0/1
//                 KCmean_st = (KCmean_st.array() > 0.0).cast<double>();


//                 // Then compute each compartment’s sparsity
//                 for (int comp = 0; comp < n_compartments; ++comp) {
//                     double sum = 0.0;
//                     for (int kc : compartment_kcs[comp]) {
//                         // Now row(kc).mean() is the fraction of odors in which KC 'kc' fired
//                         sum += KCmean_st.row(kc).mean();
//                     }
//                     comp_sparsities[comp] = sum / compartment_kcs[comp].size();
//                 }
                

//                 // Update scalars for each compartment
//                 // TO BE REVIEWED
                
//                 for (int comp = 0; comp < n_compartments; ++comp) {
//                     /* single delta method 
//                     double delta = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;

//                     wAPLKC_scales[comp] += delta;
//                     wKCAPL_scales[comp] += delta / double(p.kc.N);
//                     */
                    
//                     // per compartmental delta method
//                     if (converged[comp]) continue;

//                     double delta = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;
//                     double delta_apl_kc = delta;
                    
//                     // divide by number of claws in that compartment? 
//                     double delta_kc_apl = delta / std::max(1, comp_claw_count[comp]);
//                     if (!p.kc.preset_wAPLKC){

//                     } else {
//                         rv.log(cat("rv.kc.wAPLKC_scale ", rv.kc.wAPLKC_scale));
                        
//                     }
                    
//                     wAPLKC_scales[comp] += delta_apl_kc;
//                     wKCAPL_scales[comp] += delta_kc_apl;
//                 }

//                 // Push updated scalars into rv.kc weight vectors
//                 for (unsigned claw = 0; claw < num_claws; ++claw) {
//                     int comp = rv.kc.claw_compartments(claw);
//                     assert(0 <= comp && comp < n_compartments);
//                     rv.kc.wAPLKC(claw, 0) = wAPLKC_scales[comp];
//                     rv.kc.wKCAPL(0, claw) = wKCAPL_scales[comp];
//                 }
//                 // for (int comp = 0; comp < n_compartments; ++comp) {
//                 //     if (converged[comp]) continue;

//                 //     double delta = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;

//                 //     // ---- APL→KC update ----
//                 //     if (!p.kc.preset_wAPLKC) {
//                 //         // Update each KC/claw in this compartment directly
//                 //         for (unsigned idx : compartment_kcs[comp]) {
//                 //             rv.kc.wAPLKC(idx, 0) += delta;  
//                 //         }
//                 //     } else {
//                 //         // Scale factor update
//                 //         wAPLKC_scales[comp] += delta;
//                 //         rv.log(cat("Comp ", comp, " wAPLKC_scale: ", wAPLKC_scales[comp]));
//                 //         for (unsigned idx : compartment_kcs[comp]) {
//                 //             rv.kc.wAPLKC(idx, 0) = wAPLKC_scales[comp] * wAPLKC_unscaled(idx, 0);
//                 //         }
//                 //     }

//                 //     // ---- KC→APL update ----
//                 //     double delta_kc_apl = delta / std::max<size_t>(1, compartment_kcs[comp].size());
//                 //     if (!p.kc.preset_wKCAPL) {
//                 //         for (unsigned idx : compartment_kcs[comp]) {
//                 //             rv.kc.wKCAPL(0, idx) += delta_kc_apl;
//                 //         }
//                 //     } else {
//                 //         wKCAPL_scales[comp] += delta_kc_apl;
//                 //         rv.log(cat("Comp ", comp, " wKCAPL_scale: ", wKCAPL_scales[comp]));
//                 //         for (unsigned idx : compartment_kcs[comp]) {
//                 //             rv.kc.wKCAPL(0, idx) = wKCAPL_scales[comp] * wKCAPL_unscaled(0, idx);
//                 //         }
//                 //     }
//                 // }

                



//                 /*per compartmental delta method*/
//                 rv.log(cat("number of compartments: ", n_compartments));
//                 rv.log(cat("* i=", rv.kc.tuning_iters, ", lr=", lr));
//                 for (int comp = 0; comp < n_compartments; ++comp) {
//                     double delta_A = (comp_sparsities[comp] - p.kc.sp_target) * lr / p.kc.sp_target;
//                     double delta_K = delta_A / std::max(1, comp_claw_count[comp]);
//                     std::ostringstream comp_s;
//                     comp_s << std::fixed << std::setprecision(4) << comp_sparsities[comp];
//                     rv.log(cat("  Comp ", comp,
//                             " | sp=", comp_s.str(),
//                             " | delta_A=", delta_A,
//                             " | delta_K=", delta_K,
//                             " | scale_A=", wAPLKC_scales[comp],
//                             " | scale_K=", wKCAPL_scales[comp]));
//                 }

//                 // TODO delete
//                 // for debugging + trying to support scaling of arbitrary positive
//                 // vector wAPLKC/wKCAPL inputs
//                 if (p.kc.preset_wAPLKC) {
//                     // collect unique APL→KC scales
//                     std::set<double> uniqA;
//                     for (int i = 0; i < rv.kc.wAPLKC.rows(); ++i)
//                         uniqA.insert(rv.kc.wAPLKC(i, 0));

//                     // log only the count of unique scales
//                     std::ostringstream ossA;
//                     ossA << "number of unique wAPLKC scales: " << uniqA.size();
//                     rv.log(ossA.str());
//                 }

//                 if (p.kc.preset_wKCAPL) {
//                     // collect unique KC→APL scales
//                     std::set<double> uniqK;
//                     for (int i = 0; i < rv.kc.wKCAPL.cols(); ++i)
//                         uniqK.insert(rv.kc.wKCAPL(0, i));

//                     // log only the count of unique scales
//                     std::ostringstream ossK;
//                     ossK << "number of unique wKCAPL scales: " << uniqK.size();
//                     rv.log(ossK.str());
//                 }
                

//                 rv.kc.tuning_iters++;
//             }

//             //rv.log(cat("** t", omp_get_thread_num(), " @ before testing"));
//             /* Run through a bunch of odors to test sparsity. */


           

//             //rv.log(cat("** t", omp_get_thread_num(), " @ after testing"));

// #pragma omp single
//             {

//                 KCmean_st = (KCmean_st.array() > 0.0).select(1.0, KCmean_st);
//                 sp = KCmean_st.mean();
//                  double active_kcs = KCmean_st.sum();
//                 rv.log(cat("Iteration ", rv.kc.tuning_iters, " | Total active KCs: ", active_kcs));

//                  // Binarize responses
                    
            
//                 // Reset per-compartment sparsity accumulators
//                 std::fill(comp_sparsities.begin(), comp_sparsities.end(), 0.0);  // FOR SPARSITY CHECK
            
//                 // Compute new sparsities
//                 for (int comp = 0; comp < n_compartments; ++comp) {
//                     double sum = 0.0;
//                     for (int kc : compartment_kcs[comp]){
//                         sum += KCmean_st.row(kc).mean();
//                         comp_sparsities[comp] = sum / compartment_kcs[comp].size();
//                     }
//                 }
//             }
            
//             // format global sparsity to 4 decimal places
//             std::ostringstream sp_ss;
//             sp_ss << std::fixed << std::setprecision(4) << sp;

//             rv.log(cat("** t", omp_get_thread_num(),
//                     " @ before bottom cond [",
//                     "sp=", sp_ss.str(),
//                     ", i=", rv.kc.tuning_iters,
//                     ", tgt=", p.kc.sp_target,
//                     ", acc=", p.kc.sp_acc,
//                     ", I=", p.kc.max_iters,
//                     "]"));

//         // logic if calculating per compartmental deltas
//         // int n_converged = 0;
//         // static std::vector<int> consec_within(n_compartments, 0);
//         // const int K = 2;  // require 2 consecutive iterations within tolerance
//         // for (int comp = 0; comp < n_compartments; ++comp) {
//         //     double rel_diff = std::abs(comp_sparsities[comp] - p.kc.sp_target) / p.kc.sp_target;
//         //     if (rel_diff <= p.kc.sp_acc) consec_within[comp]++; else consec_within[comp] = 0;
//         //     converged[comp] = (consec_within[comp] >= K);
//         //     if (converged[comp]) n_converged++;
//         // }
//         int n_converged = 0;
//         for (int comp = 0; comp < n_compartments; ++comp) {
//             double rel_diff = std::abs(comp_sparsities[comp] - p.kc.sp_target) / p.kc.sp_target;
//             bool within = (rel_diff <= p.kc.sp_acc);
//             converged[comp] = within;   // <-- overwrite every iteration
//             if (within) n_converged++;
//         }
//         if (n_converged == n_compartments) {
//             rv.log("All compartments converged!");
//             break;
//         }
//         if (rv.kc.tuning_iters > p.kc.max_iters) {
//             rv.log("WARNING: Max iterations reached. Some compartments may not have converged.");
//             break;
//         }
//         // two deltas method
//         } 
        
//         // original single delta method
//         // while ((abs(sp - p.kc.sp_target) > (p.kc.sp_acc * p.kc.sp_target))
//         //         && (rv.kc.tuning_iters <= p.kc.max_iters)); 
//         //rv.log(cat("** t", omp_get_thread_num(), " @ exit"));
// #pragma omp barrier
// #pragma omp single
//         {
//             rv.kc.tuning_iters--;
//         }
//     }}

//     // Declare exactly the same temporaries used inside the tuner:
//     Matrix Vm_end(p.kc.N,    p.time.steps_all());
//     Matrix spikes_end(p.kc.N, p.time.steps_all());
//     Matrix nves_end(p.kc.N,   p.time.steps_all());
//     Matrix inh_end(n_compartments, p.time.steps_all()), Is_end(n_compartments, p.time.steps_all());

//     // Build a response matrix exactly as in the tuning loop: one column per subsampled odor
//     unsigned nCols = 1 + ((tlist.size() - 1) / p.kc.apltune_subsample);
//     Matrix resp(p.kc.N, nCols);

//     for (unsigned i = 0; i < tlist.size(); i += p.kc.apltune_subsample) {
//         // run a KC sim exactly as you do above
//         sim_KC_layer(p, rv,
//             rv.pn.sims[tlist[i]],
//             rv.ffapl.vm_sims[tlist[i]],
//             Vm_end, spikes_end, nves_end, inh_end, Is_end, KC_row);

//             // sum across time, then binarize  
//         resp.col(i / p.kc.apltune_subsample) =
//             (spikes_end.rowwise().sum().array() > 0.0).cast<double>();
//     }
 
//     double overallS = resp.mean();
//     rv.log(cat("Overall sparsity after tuning: ", overallS));

//     // TODO delete?
//     // rv.log(cat("FINAL rv.kc.wAPLKC_scale: ", rv.kc.wAPLKC_scale));
//     // rv.log(cat("FINAL rv.kc.wKCAPL_scale: ", rv.kc.wKCAPL_scale));

//     // TODO always log tuned parameters at end (fixed_thr, wAPLKC/wKCAPL when not
//     // preset, or wAPLKC_scale/wKCAPL_scale when preset)
//     rv.log("done fitting sparseness");
// }